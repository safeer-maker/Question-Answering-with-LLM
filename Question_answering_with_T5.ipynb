{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Create a question answer section using T5 or other model on eli5 dataset.\n",
    "\n",
    "If we use smaller llm models they can give the answer of the question but failed to give answer in human manner.\n",
    "I have pre tained the bert model but it will only provide the extraceted asnwer. By extracted it mean the exact words will be generated againt the question.\n",
    "\n",
    "Lets make it more fun. I think to use FIAS sementic serach for extraction relavent documents ffrom the model and then provide the text to the model for proper human answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "from transformers import T5TokenizerFast\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train_eli5: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 272634\n",
       "    })\n",
       "    validation_eli5: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 9812\n",
       "    })\n",
       "    test_eli5: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 24512\n",
       "    })\n",
       "    train_asks: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 131778\n",
       "    })\n",
       "    validation_asks: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 2281\n",
       "    })\n",
       "    test_asks: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 4462\n",
       "    })\n",
       "    train_askh: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 98525\n",
       "    })\n",
       "    validation_askh: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 4901\n",
       "    })\n",
       "    test_askh: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "        num_rows: 9764\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"eli5\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets combine the dataset as we only need to answer the question on all the possible topic we can have\n",
    "\n",
    "WE are not going to train our model on this dataset. Insted we need to use this information for our sementic search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_eli5',\n",
       " 'validation_eli5',\n",
       " 'test_eli5',\n",
       " 'train_asks',\n",
       " 'validation_asks',\n",
       " 'test_asks',\n",
       " 'train_askh',\n",
       " 'validation_askh',\n",
       " 'test_askh']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_titles = list (dataset.keys() )\n",
    "dataset_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '3ko13p',\n",
       " 'title': 'In the latest Avengers movie, there is a \"Nexus\" hub which routes every packet of traffic on the internet. What is the closest thing we have to a core of the internet in real life?',\n",
       " 'selftext': '',\n",
       " 'document': '',\n",
       " 'subreddit': 'askscience',\n",
       " 'answers': {'a_id': ['cuz3k5a',\n",
       "   'cuz2ili',\n",
       "   'cuz3zwf',\n",
       "   'cuz2kz8',\n",
       "   'cuz3e8d',\n",
       "   'cuz2y2h',\n",
       "   'cuz3p8y',\n",
       "   'cuz3mot',\n",
       "   'cuzaunl',\n",
       "   'cuztchh',\n",
       "   'cuz2j6p'],\n",
       "  'text': [\"Hey, Network Engineer here! \\n\\n (please don't get mad at me mechanical/electrical/etc engineers, it's just a job title.)\\n\\nThat idea is actually the exact opposite of how the internet works. (funny enough Cisco, a major networking vendor, has a line of switches called Nexus.)\\n\\nStrictly speaking the internet routing is completely distributed.  The BGP protocol is how that routing table is updated and hundreds of thousands of people/companies update the table regularly.   Those updates include    the destination  information and how-to-get-here information (IP and AS PATH).    In fact, often times the path you take to get to one place will be different from the path the traffic takes to get back to you!  Outside of a single Autonomous System (usually a company / ISP)  people are more interested in taking advantage of the best route available to them than anything mainly because those internet links are expensive.\\n\\nA lot of the heavy lifting comes in from the ISPs of course,  you have multiple tiers of ISPs and they're all of the world... but this doesn't centralize anything further at all.   Funny enough because of the way BGP works, if these providers aren't doing things 100% air tight  an accidental configuration can bring large chunks of the internet down.\\n\\nsee:\\n\\n   _URL_1_\\n\\n   _URL_2_\\n\\nboth of those links deal with the architecture of the internet and the exact thing you asked about.   A czech provider had accidentally updated their little slice of the internet wrong and brought a large portion of it down for about a half hour... people took notice.\\n\\nWe know that governments have done inline taps on fiber links, sometimes at a large scale - which is sort of like what you're talking about.  \\n\\nSo much so that google is now encrypting their internal traffic..: \\n\\n   _URL_0_\\n    \\nBut there's really no central point of failure with the internet, though there's plenty of ways to make it fail.\",\n",
       "   'The Internet is decentralized and by design has no single \"choke point\" for data. However, there are multiple companies who are considered Tier One Internet providers. This means that they build large networks and provide connection to other tier one providers for other smaller Internet Service Providers (isp\\'s). A tier one provider may also be an isp (Verizon and AT & T are both considered tier one providers) or can just provide routing and connection services to ISP\\'s and not end users (Level 3 in the US, for example).\\n\\nSource: Had some networking classes in college and Wikipedia.',\n",
       "   \"I think that the closest you are going to find to the Nexus Hub from the movie is an [Internet Exchange](_URL_5_). These are basically just locations where networks meet. The first major Exchange was [MAE East](_URL_6_), which actually was basically a single centralized point that most internet traffic routed to. \\n\\nAt one point it was the main way for traffic to be exchanged between ISPs. For example, before DE-CIX went in in Germany, the three telecoms there all routed their traffic across the ocean to MAE East, even if it was just going to connect to one of the other German ISPs. Eventually they realized this was really really really slow, so they started an exchange in Frankfurt, Germany (DE-CIX).\\n\\nIf you are really interested in this, I would highly recommend reading [Tubes: A Journey to the Center of the Internet](_URL_6_). It is very well written, and although I was already familiar with most of the internals of how things worked, it definitely isn't required to already understand the process. \\n\\nEdit: I also found [this list of internet exchanges by size](_URL_4_)\",\n",
       "   'Part of the beauty of the internet is that there doesn\\'t really need to be a \"core\" in the common sense. There does have to be a centralized domain name management system, but the internet itself could function without that - you\\'d just have to memorize a lot of IP addresses because there would be no guarantee that only one person has a domain name (in theory DNS could still work, but there would be no guarantees of your destination).\\n\\nIn terms of critical infrastructure and protocols, I think the Border Gateway Protocol, and its associated routers, would be the closest you can get. According to one of my old textbooks, which I sadly no longer have, disabling BGP routers (or even configuring them incorrectly) can cause large swaths of geographic territory to disappear from the internet.\\n\\nWhile it\\'s not peer-reviewed or a textbook, [this site](_URL_7_) explains the importance of the protocol itself and of configuring the routers securely and correctly.\\n\\nI\\'ve been out of the field for a while now, so if anyone else has additional information on this, I\\'d love to hear another opinion.',\n",
       "   \"DNS root servers. There's 13 of them, in the world. I believe that at one point, the military owner the majority of them and decided to make them more public, and turned over control to schools and authoritative bodies. \\n\\nDNS changes a name or word into a number, and a number to a name. When you go to _URL_8_, your computer requests the IP for that site. Your local DNS server will more than likely have this IP and give it to you. Then, your computer reaches out to that IP, and the next thing you know, you're looking up funny cat videos. \\n\\nBut, what happens if your local DNS server doesn't know about the website you request? It has a kind of parent DNS server, and it will make the same request to its parent. As you go up the chain, you start getting less and less servers, until you're left with the 13 root servers. Not a single Nexus, but definitely the closest thing we have to it. \\n\\nYou can also go from IP to name. Nslookup 8.8.8.8 will resolve to a Google server. In this case, it's google's public DNS, free to use by anyone. \\n\\nAlong the same lines, the dark net is only dark because it's not registered in DNS. You have to know how to get where you're going, DNS won't help you.\",\n",
       "   'There are big fiber optic hubs operated by the big telcos in the United States. Their existence allowed the NSA to more or less tap large chunks of the US internet and all traffic entering or exiting the US.\\n\\n_URL_9_',\n",
       "   \"There isn't a single hub, but what you are looking for are called the DNS root name servers. These 13 server farms, located around the world, hold the ultimate key that decides where each packet travels on the internet (for all intents and purposes. There are some exceptions, but I won't go into them here). DNS, or domain name service, is what translates *_URL_10_ to *204.85.30.102*. It takes the URL you put in the address bar and converts it to the IP address registered to that URL. This is important because computers don't inherently know which computer is at which URL. They have to look up the IP address first, and then they can use that tot communicate. \\n\\nDNS does the job of translating URLs to IP addresses for your computer. Without this service, you can't access the internet unless you know which IP address you are trying to get to. There are multiple levels of DNS, from the local cache that is stored on some computers, to the caches stored by Tier 1 and 2 ISPs (internet service providers), all the way up to the DNS root name servers. These root name servers are the end all be all for routing IP packets. If they were updated to say that *_URL_11_* was registered to the IP address *31.192.117.132* then you would be automatically redirected to _URL_12_ everytime you typed _URL_13_ into the URL address bar at the top of your browser.\",\n",
       "   \"I haven't done network work for a while so my information is likely dated, but the closest one came to anything similar to a Nexus hub ten years ago would be a Metropolitan Area Exchange (MAE). For example, there was MAE-East in the Washington, D.C. and MAE-West in the San Jose. That said, Internet Protocols do not rely on such central services, so if they went away, the net could route around them.\",\n",
       "   'To add to what others are saying. The lack of a core to the internet was done deliberately by those who designed it for the purpose of preventing any one entity from being able to control it. The \"Nexus\" hub was something that was deliberately made not possible by the engineers who created the internet. \\n\\nAs a side effect of this, it also means your content loads faster because it does not have to travel all the way to the hub and all the way back.',\n",
       "   \"I work with Cisco routers. There is one box the size of a refrigerator that routes about 8 Terabits per second. It can transfer the entire contents of a 1 Terabyte drive every second. It's used in cloud and core network applications. This type of box is the backbone of most core networks over which Internet traffic is routed. As others have answered, there are multiple circuits and multiple routers between the various endpoints on the Internet, so there is really no such thing as a single 'hub'. Probably the best way to bring down the modern Internet would be to poison several root DNS servers, which would interfere with network hosts and smaller DNS servers from successfully looking up IP addresses for hostnames.\",\n",
       "   \"There is no good answer. How would you define the core? In the movie, if every packet went through it, then it would be the most used or travelled hub.\\n\\nTo ask a similar question to highlight the problem... What would you say in the core of America's roadways? Which intersection?\\n\\nEven if the intersection was demolished, it may slow down traffic, but cars could take alternate routes. The best you could answer is the most trafficked intersection or node.\"],\n",
       "  'score': [177, 27, 26, 10, 8, 7, 5, 5, 4, 2, 2]},\n",
       " 'title_urls': {'url': []},\n",
       " 'selftext_urls': {'url': []},\n",
       " 'answers_urls': {'url': ['http://www.infoworld.com/article/2612729/cringely/what-s-on-tap-at-the-nsa--google-s-and-yahoo-s-private-fiber-backbones.html',\n",
       "   'http://research.dyn.com/2009/02/the-flap-heard-around-the-world/',\n",
       "   'http://research.dyn.com/2009/02/longer-is-not-better/',\n",
       "   'https://en.wikipedia.org/wiki/MAE-East',\n",
       "   'https://en.wikipedia.org/wiki/List_of_Internet_exchange_points_by_size',\n",
       "   'https://en.wikipedia.org/wiki/Internet_exchange_point',\n",
       "   'http://www.amazon.com/Tubes-A-Journey-Center-Internet/dp/0061994952',\n",
       "   'http://www.enterprisenetworkingplanet.com/netsp/article.php/3615896/Networking-101-Understanding-BGP-Routing.htm',\n",
       "   'google.com',\n",
       "   'https://en.wikipedia.org/wiki/Room_641A',\n",
       "   'http://www.google.com/*',\n",
       "   'www.google.com/',\n",
       "   'www.pornhub.com',\n",
       "   'google.com']}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test_asks'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': ['1xa1l8', '3ko13p', '2jy57p', '1943xl', '98va8l'],\n",
       " 'title': [\"If the heart is just a muscle, why can't I voluntarily flex it, or move it in any way?\",\n",
       "  'In the latest Avengers movie, there is a \"Nexus\" hub which routes every packet of traffic on the internet. What is the closest thing we have to a core of the internet in real life?',\n",
       "  \"Can somebody give me an intuitive understanding of Sine, Cosine, Tangent and perhaps Cotangent, Secant, Cosecant in such a way I won't forget?\",\n",
       "  \"I've seen a magnet being dropped down a copper pipe... what happens if you do the opposite?\",\n",
       "  'What is the del operator in the Schrodinger equation?'],\n",
       " 'selftext': [\"Oftentimes, when when I focus on my heartbeat, I start to freak out that I might accidentally tell it to stop, or think something irrational like I could make it start beating manually, and then be stuck forever having to concentrate to contract my own heart to keep from dying. \\n\\nIf the heart is just a basic muscle, why can't I control it? I know there are many autonomous processes in the human body, but I'm just wondering what, if anything, caused it to be completely out of the conscious control? Was it evolutionarily selected for at some really early stage? Or is it essential for life that it just be that way?\",\n",
       "  '',\n",
       "  \"I use them all the time for equations but they might as well be Greek for me. I just want to perfectly understand as much as possible what's happening when I throw these into the calculator. I haven't had trigonometry as of yet.   \",\n",
       "  'If you had a magnetic tube, and dropped a piece of copper down it.  Would it build eddy currents and slow the piece of copper down?',\n",
       "  ''],\n",
       " 'document': ['', '', '', '', ''],\n",
       " 'subreddit': ['askscience',\n",
       "  'askscience',\n",
       "  'askscience',\n",
       "  'askscience',\n",
       "  'askscience'],\n",
       " 'answers': [{'a_id': ['cf9gyt1', 'cf9h410', 'cf9i6b2'],\n",
       "   'text': ['Muscles are grouped in either voluntary or involuntary muscle. From there it breaks down into skeletal\\n muscle ( biceps triceps etc) which is considered voluntary, smooth muscle is involuntary, this includes the muscles in your intestines to digest food or pupils in your eyes to dilatue or not, and lastly to answer your question there is cardiac muscle. It is also involuntary. It is able to generate its own stimulus to contract when i needed. \\n\\n\\nSorry for errors. On phone :p',\n",
       "    \"Cardiac tissue isn't under voluntary control. The parts of the brain that control things like breathing, digestion, heartbeat ect are controllable only to a certain extent. For example, if you concentrate you can slow your heart rate, but it will keep beating. Similarly you can control your breathing, but you can't make yourself suffocate by holding your breath, because eventually your body will force you to breath again. I'm not sure how this has evolved, but it certainly works out for the best that way. Ever thought about trying to control your blinking? Talk about maddening....\",\n",
       "    \"In the body there are two types of muscle cells: striated (skeletal muscles) and smooth muscles (found in blood vessels, intestines, under your skin (goosebumps), etc). Basically the only muscles that you can influence at will, are skeletal muscles.\\n\\nEmbryologically the heart is formed from the same tissue as the blood vessels are. In blood vessels, only smooth muscles are found. They contract to increase bloodpressure, mostly.\\n\\nBut the heart is a different organ, it has to be almost constantly active, it can relax between to heartbeats, but that's it. All other muscular tissue in your body can relax for hours on end. Not the heart. So the muscle fibers of the heart have differentiated and aren't exactly smooth muscle fibers anymore. They're some sort of cross breed that has the property to function 'by itself', and can continue to contract without getting damaged. \\n\\nThe heart is influenced by the autonomous nervous system, which influences heart rate, bloodpressure, etc. To some extent you could technically influence that consciously: for instance when you are scared or by relaxing, or by stressing out, or taking deep breaths. To some extent, you can influence your heartrate, but as long as the heart (the conductive system included) is in good shape, you can't make your heart stop beating at will. And all the ways that you influence your heartrate are indirect, never direct. You can't think 'Ah, lets to 50bpm now' or 150bpm for that matter...\\n\\nSources:\\n\\n* _URL_1_\\n* _URL_0_\"],\n",
       "   'score': [13, 6, 4]},\n",
       "  {'a_id': ['cuz3k5a',\n",
       "    'cuz2ili',\n",
       "    'cuz3zwf',\n",
       "    'cuz2kz8',\n",
       "    'cuz3e8d',\n",
       "    'cuz2y2h',\n",
       "    'cuz3p8y',\n",
       "    'cuz3mot',\n",
       "    'cuzaunl',\n",
       "    'cuztchh',\n",
       "    'cuz2j6p'],\n",
       "   'text': [\"Hey, Network Engineer here! \\n\\n (please don't get mad at me mechanical/electrical/etc engineers, it's just a job title.)\\n\\nThat idea is actually the exact opposite of how the internet works. (funny enough Cisco, a major networking vendor, has a line of switches called Nexus.)\\n\\nStrictly speaking the internet routing is completely distributed.  The BGP protocol is how that routing table is updated and hundreds of thousands of people/companies update the table regularly.   Those updates include    the destination  information and how-to-get-here information (IP and AS PATH).    In fact, often times the path you take to get to one place will be different from the path the traffic takes to get back to you!  Outside of a single Autonomous System (usually a company / ISP)  people are more interested in taking advantage of the best route available to them than anything mainly because those internet links are expensive.\\n\\nA lot of the heavy lifting comes in from the ISPs of course,  you have multiple tiers of ISPs and they're all of the world... but this doesn't centralize anything further at all.   Funny enough because of the way BGP works, if these providers aren't doing things 100% air tight  an accidental configuration can bring large chunks of the internet down.\\n\\nsee:\\n\\n   _URL_1_\\n\\n   _URL_2_\\n\\nboth of those links deal with the architecture of the internet and the exact thing you asked about.   A czech provider had accidentally updated their little slice of the internet wrong and brought a large portion of it down for about a half hour... people took notice.\\n\\nWe know that governments have done inline taps on fiber links, sometimes at a large scale - which is sort of like what you're talking about.  \\n\\nSo much so that google is now encrypting their internal traffic..: \\n\\n   _URL_0_\\n    \\nBut there's really no central point of failure with the internet, though there's plenty of ways to make it fail.\",\n",
       "    'The Internet is decentralized and by design has no single \"choke point\" for data. However, there are multiple companies who are considered Tier One Internet providers. This means that they build large networks and provide connection to other tier one providers for other smaller Internet Service Providers (isp\\'s). A tier one provider may also be an isp (Verizon and AT & T are both considered tier one providers) or can just provide routing and connection services to ISP\\'s and not end users (Level 3 in the US, for example).\\n\\nSource: Had some networking classes in college and Wikipedia.',\n",
       "    \"I think that the closest you are going to find to the Nexus Hub from the movie is an [Internet Exchange](_URL_5_). These are basically just locations where networks meet. The first major Exchange was [MAE East](_URL_6_), which actually was basically a single centralized point that most internet traffic routed to. \\n\\nAt one point it was the main way for traffic to be exchanged between ISPs. For example, before DE-CIX went in in Germany, the three telecoms there all routed their traffic across the ocean to MAE East, even if it was just going to connect to one of the other German ISPs. Eventually they realized this was really really really slow, so they started an exchange in Frankfurt, Germany (DE-CIX).\\n\\nIf you are really interested in this, I would highly recommend reading [Tubes: A Journey to the Center of the Internet](_URL_6_). It is very well written, and although I was already familiar with most of the internals of how things worked, it definitely isn't required to already understand the process. \\n\\nEdit: I also found [this list of internet exchanges by size](_URL_4_)\",\n",
       "    'Part of the beauty of the internet is that there doesn\\'t really need to be a \"core\" in the common sense. There does have to be a centralized domain name management system, but the internet itself could function without that - you\\'d just have to memorize a lot of IP addresses because there would be no guarantee that only one person has a domain name (in theory DNS could still work, but there would be no guarantees of your destination).\\n\\nIn terms of critical infrastructure and protocols, I think the Border Gateway Protocol, and its associated routers, would be the closest you can get. According to one of my old textbooks, which I sadly no longer have, disabling BGP routers (or even configuring them incorrectly) can cause large swaths of geographic territory to disappear from the internet.\\n\\nWhile it\\'s not peer-reviewed or a textbook, [this site](_URL_7_) explains the importance of the protocol itself and of configuring the routers securely and correctly.\\n\\nI\\'ve been out of the field for a while now, so if anyone else has additional information on this, I\\'d love to hear another opinion.',\n",
       "    \"DNS root servers. There's 13 of them, in the world. I believe that at one point, the military owner the majority of them and decided to make them more public, and turned over control to schools and authoritative bodies. \\n\\nDNS changes a name or word into a number, and a number to a name. When you go to _URL_8_, your computer requests the IP for that site. Your local DNS server will more than likely have this IP and give it to you. Then, your computer reaches out to that IP, and the next thing you know, you're looking up funny cat videos. \\n\\nBut, what happens if your local DNS server doesn't know about the website you request? It has a kind of parent DNS server, and it will make the same request to its parent. As you go up the chain, you start getting less and less servers, until you're left with the 13 root servers. Not a single Nexus, but definitely the closest thing we have to it. \\n\\nYou can also go from IP to name. Nslookup 8.8.8.8 will resolve to a Google server. In this case, it's google's public DNS, free to use by anyone. \\n\\nAlong the same lines, the dark net is only dark because it's not registered in DNS. You have to know how to get where you're going, DNS won't help you.\",\n",
       "    'There are big fiber optic hubs operated by the big telcos in the United States. Their existence allowed the NSA to more or less tap large chunks of the US internet and all traffic entering or exiting the US.\\n\\n_URL_9_',\n",
       "    \"There isn't a single hub, but what you are looking for are called the DNS root name servers. These 13 server farms, located around the world, hold the ultimate key that decides where each packet travels on the internet (for all intents and purposes. There are some exceptions, but I won't go into them here). DNS, or domain name service, is what translates *_URL_10_ to *204.85.30.102*. It takes the URL you put in the address bar and converts it to the IP address registered to that URL. This is important because computers don't inherently know which computer is at which URL. They have to look up the IP address first, and then they can use that tot communicate. \\n\\nDNS does the job of translating URLs to IP addresses for your computer. Without this service, you can't access the internet unless you know which IP address you are trying to get to. There are multiple levels of DNS, from the local cache that is stored on some computers, to the caches stored by Tier 1 and 2 ISPs (internet service providers), all the way up to the DNS root name servers. These root name servers are the end all be all for routing IP packets. If they were updated to say that *_URL_11_* was registered to the IP address *31.192.117.132* then you would be automatically redirected to _URL_12_ everytime you typed _URL_13_ into the URL address bar at the top of your browser.\",\n",
       "    \"I haven't done network work for a while so my information is likely dated, but the closest one came to anything similar to a Nexus hub ten years ago would be a Metropolitan Area Exchange (MAE). For example, there was MAE-East in the Washington, D.C. and MAE-West in the San Jose. That said, Internet Protocols do not rely on such central services, so if they went away, the net could route around them.\",\n",
       "    'To add to what others are saying. The lack of a core to the internet was done deliberately by those who designed it for the purpose of preventing any one entity from being able to control it. The \"Nexus\" hub was something that was deliberately made not possible by the engineers who created the internet. \\n\\nAs a side effect of this, it also means your content loads faster because it does not have to travel all the way to the hub and all the way back.',\n",
       "    \"I work with Cisco routers. There is one box the size of a refrigerator that routes about 8 Terabits per second. It can transfer the entire contents of a 1 Terabyte drive every second. It's used in cloud and core network applications. This type of box is the backbone of most core networks over which Internet traffic is routed. As others have answered, there are multiple circuits and multiple routers between the various endpoints on the Internet, so there is really no such thing as a single 'hub'. Probably the best way to bring down the modern Internet would be to poison several root DNS servers, which would interfere with network hosts and smaller DNS servers from successfully looking up IP addresses for hostnames.\",\n",
       "    \"There is no good answer. How would you define the core? In the movie, if every packet went through it, then it would be the most used or travelled hub.\\n\\nTo ask a similar question to highlight the problem... What would you say in the core of America's roadways? Which intersection?\\n\\nEven if the intersection was demolished, it may slow down traffic, but cars could take alternate routes. The best you could answer is the most trafficked intersection or node.\"],\n",
       "   'score': [177, 27, 26, 10, 8, 7, 5, 5, 4, 2, 2]},\n",
       "  {'a_id': ['clg9vcq',\n",
       "    'clga65f',\n",
       "    'clga5ty',\n",
       "    'clgdvfu',\n",
       "    'clgfgtc',\n",
       "    'clggnpk',\n",
       "    'clg82u3',\n",
       "    'clgdfp1',\n",
       "    'clgcwis',\n",
       "    'clgc0x7',\n",
       "    'clgjuh4',\n",
       "    'clg78d1',\n",
       "    'clgyp1o',\n",
       "    'clgfaq6',\n",
       "    'clgf306',\n",
       "    'clgezvl',\n",
       "    'clguhb8',\n",
       "    'clgmhuj',\n",
       "    'clgrwdo',\n",
       "    'clgj9q3',\n",
       "    'clgs3dy',\n",
       "    'clgk00f',\n",
       "    'clgj2dp'],\n",
       "   'text': [\"The cosine and sine functions give the coordinates of points on the [unit circle](_URL_0_): The point at angle t on the unit circle has coordinates (cos(t), sin(t)).\\n\\nApplying the Pythagorean theorem to the triangle with vertices (0, 0), (cos(t), 0), and (cos(t), sin(t)), the above definition implies that 1 = cos(t)^2 + sin(t)^2 for all t. Many commonly encountered trigonometric identities are just restatements of this fact.\\n\\nTangent, cotangent, secant, and cosecant are just various ratios of sine and cosine, and they're not quite as important. (Whenever I encounter those functions, the first thing I usually do is write them in terms of sine and cosine.) You can [interpret them geometrically](_URL_1_), but it's probably easier to remember how they're defined in terms of sine and cosine.\",\n",
       "    \"Think of a graph with a circle around the origin (where x and y equal zero). So, each quarter of the graph has a quarter of a circle in it, right?\\n\\nNow, suppose I draw a straight line from the center to some point on the circle. For now let's say I drew it diagonally right and up. Here's what I want to know: How far to right have I gone, and how far up have I gone? You can also picture a right triangle, where the line we drew is the diagonal of the triangle, and the x and y straight lines are the two other sides. What are the lengths of those sides?\\n\\nWell, we can find out what those lengths are, simply by knowing where on the circle we are. The x vaule is the Cosine, and the y value is the Sine.\\n\\nIf the circle has a radius of 1, and we went, say, 45 degrees around the full 360 degree circle (you can also use 'radians', where all the way 360 around the circle is equal to 2pi, so 45 degrees would be pi/4). So, cos(pi/4), or cos(45desgres) = sqrt(2)/2, or about 0.707 on your calculator.\\n\\nAlso, sin(pi/4) = sqrt(2)/2. The same thing. This makes sense, because we're going exactly diagonal, so we're the same distance right as we are up.\\n\\nIf you put in something like cos(90degrees), or cos(pi/2), you get zero. Why? Because we're going straight up, the x value is zero, of course. Also the sin is 1, because the radius is 1, and the y value is the whole thing when going straight up like that.\\n\\nWhat if the circle has a radius of 2? Easy, just multiply by 2.\\n\\nWhat about Tangent? Tangent is just Sin/Cos at any given point.\\n\\nThe others? They're just 1/Cos, 1/Sin, and 1/Tan respectively. You don't really even need to use the other names.\\n\\nLet me know if you have any questions.\",\n",
       "    'I find visualizing the functions is a good way to grasp them on an intuitive level.  These animations may help:\\n\\n_URL_2_\\n\\n_URL_3_',\n",
       "    \"Wow, a lot of these explanations are overly complicated.  Sine, cosine, and tangent functions just convert between angle and distance in an x/y coordinate plane.  If, starting on the positive x axis on the unit circle, I rotate through an angle of x around the origin, then the following are true:\\n\\n-My position along the x axis is cos(x).\\n\\n-My position along the y axis is sin(x).\\n\\n-The angle of the line formed between the origin and the point I am at is tan(x).\\n\\nThat's really all there is to it.  A few easy examples:  Sin(0)=0, cos(0)=1, sin(90*)=1, cos(90*)=0, sin(30*)=1/2.\\n\\nYou can use the functions to find angles and side lengths of triangles because they relate angle to distance in this way.\",\n",
       "    'They are all just shorthand names for functions that expresses a ratio of the sides of a right triangle. Because a right triangle can fit within a unit circle, these functions can be used with both cartesian and polar coordinate systems.\\n\\nWhile memorizing without understanding is not great, all of the functions can be derived by understanding the ratios they express. And, effectively, **all can be derived from tangent**.  So, if you are going to memorize anything, **memorize tangent**.\\n\\nFirst, some background ... \\n\\nA right triangle has three sides that have names relative to their location. One angle is the right angle (which is the corner whose angle is 90 degrees in cartesian coordinates, and π/2 radians in polar coordinates). It is opposite the side of the triangle called the hypotenuse. That is, *hypotenuse* is the word that defines the name of the side of a right triangle that is opposite the right angle.\\n\\nTaking the perspective of the other two interior angles, one side non-hypotenuse side of the triangle is *adjacent* to the angle, and the other non-hypotenuse side is the *opposite* side.\\n\\nThe *tangent* of that angle is the ratio of the length of the *opposite* side divided by the length of the *adjacent* side.\\nThat is, *tangent* is *opposite* over *adjacent*.\\n\\nExpressed in equation form ... \\n\\n                       opposite\\n         tan(angle) = ——————————\\n                       adjacent\\n    \\nThe *sine* of a non-right angle in a right triangle is also a ratio of sides ... *opposite* over *hypotenuse*.\\n\\n                       opposite\\n         sin(angle) = ——————————\\n                      hypotenuse\\n    \\nThe *cosine* of a non-right angle in a right triangle is the ratio of the length of the *adjacent* side divided by the length of the *hypotenuse*.\\n\\n                          adjacent\\n         cos(angle) =  ———————————————\\n                         hypotenuse\\n    \\nSo, substitute and realize how *tangent* can be defined in terms of *sine* and *cosine*. \\n\\n                 opposite    opposite/hypotenuse    sin(angle) \\n    tan(angle) = ————————— = ———————————————————— = ——————————— \\n                 adjacent    adjacent/hypotenuse    cos(angle)\\n\\nMore concisely ...\\n\\n                   op     op/hyp     sin(θ)\\n        tan(θ) =  ———— =  ——————— = ———————\\n                   adj    adj/hyp    cos(θ)\\n\\nThere are three other trigonometic functions that are just inversions of tangent, sine and cosine.  But they are named in a confusing way.\\n\\nCotangent is the inversion of tangent.\\n\\nCosecent is the inversion of sine.\\n\\nSecant is the inversion of cosine.\\n\\nSince *cotangent* is simply the inversion of *tangent* ... \\n\\n                    1         1       adj       adj/hyp    cos(θ)  \\n        cot(θ) = ——————— = ——————— = ——————  =  ——————— =  ———————\\n                  tan(θ)    op/adj     op        op/hyp    sin(θ)\\n\\nThe *cosecant* (shorthand notation is *csc*) function of an angle is the ratio of the length of the *hypotenuse* divided by the length of the *opposite* side.\\n\\n                 hyp     1        1\\n        csc(θ) = ——— = —————— = —————— \\n                  op   op/hyp    sin(θ)\\n\\nThe *secant* (shorthand notation is *sec*) function of an angle is the *hypotenuse* divided by the *adjacent* side.\\n\\n                 hyp     1         1\\n        sec(θ) = ——— = —————— = ——————— \\n                  adj  adj/hyp    cos(θ)\\n\\n*Cotangent* can also be expressed in terms of *secant* and *cosecant*.\\n\\n                 csc(θ)         \\n        cot(θ) = —————— \\n                 sec(θ)\\n\\n\\nAgain, you can memorize one function — *tangent* — and derive the others from that.',\n",
       "    'Think of a triangle with a square angle. The longest side is called **H**ypothenuse, the smallest (the one that is opposite the angle you\\'re interested in) would be the **O**pposite and the side that is the shortest of the two lines connected to the angle you\\'re looking at (which is not the hypothenuse) is called **A**djacent.\\n\\nNow remember this: \"SOHCAHTOA\"\\n\\nIt actually says sin=opposite/hypothenuse, cos=adjacent/hypothenuse, tan=opposite/adjacent.\\n\\nYou can very easily plot these on a circle of diameter A and center the top of the angle you\\'re studying to see which of the lengths of the triangle represents the x and y, seeing as they\\'re always separated by a right angle.',\n",
       "    'One way to understand these functions is that they are a shorthand for converting between polar coordinates and Cartesian coordinates. The point on a circle, defined x^2 + y^2 = r^2, at some particular (x_0, y_0), corresponds to a point at (r, ANGLE). If you imagine having a circle, with a known radius, (specifically the unit circle r =1), and thus a known equation, and having an angle, then the sine and cosine functions are the solutions to the problem of finding the y and x coordinates of the point on that circle denoted by the angle.',\n",
       "    \"Any angle smaller than 90 degrees can be part of a right triangle. Because you know a right triangle has one 90 degree angle, and a triangle's angles must add to 180, you can figure out the last angle.\\n\\nWith me so far?\\n\\nNow, if you have those three angles you can make an infinite number of right triangles, which are all in proportion with each other. Same angles, but the legs and hypotenuses will be different between triangles by a single multiplied value.\\n\\nThe point I'm making here is you can know a lot of information about a right triangle just by knowing one of its angles if that angle is smaller than 90 degrees.\\n\\nSine is the ratio of the length of the leg of the triangle across from the angle and the length of the hypotenuse. It looks like this:\\n\\n* sine(angle)=opposite leg/hypotenuse\\n\\nOf course, knowing that ratio isn't easy because, as far as I know, there's no easy, accurate conversion from angle to leg and hypotenuse. However, no one's asking you to do that. Your calculator or lookup table will do that for you.\\n\\nCosine is similar to sine, but it uses the length of the leg adjacent to the angle. So it looks like:\\n\\n* cosine(angle)=adjacent leg/hypotenuse\\n\\nTangent is basically the combination of sine and cosine, and it looks like this:\\n\\n* tan(angle)=opposite leg/adjacent leg=sine(angle)/cosine(angle)\\n\\nCosecant, secant, and cotangent are the multiplicative inverse functions:\\n\\n* cosecant(angle)=hypotenuse/opposite leg=1/sine(angle)\\n\\n* secant(angle)=hypotenuse/adjacent leg=1/cos(angle)\\n\\n* cotangent(angle)=adjacent leg/opposite leg=cosine(angle)/sine(angle)\\n\\nArcsine, arccosine, and arctangent are the inverse functions as sine, cosine, and tangent apply to the angle. In other words you'll plug the ratio into the function and it'll spit out the angle. They look like this:\\n\\n* arcsine(opposite leg/hypotenuse)=angle\\n\\n* arccosine(adjacent leg/hypotenuse)=angle\\n\\n* arctangent(opposite leg/adjacent leg)=angle\\n\\nAnd you also have arccosecant, arcsecant, and arccotangent, but I don't think you need me to explain those.\\n\\nAs others have said, this is important because of the right triangle's relationship with Cartesian coordinates and the unit circle.\",\n",
       "    \"Slightly off topic, but it may be interesting to know that your calculator cheats.  It converts the input into a pre-defined taylor series stored in it's memory.  For example:\\n\\n    sin(x) is approximately equal to x - x^3/(3!) + x^5/(5!) - x^7/(7!) ...\\n\\nComputers don't solve anything more complex than +, -, *, /.  The true intricacies of sine, cosine, and tangent, are far too complex to break down into 1's and O's.\",\n",
       "    \"All the others are built from sine and cosine, so I'll start with them.\\n\\nThey're shapes, or patterns if you prefer. \\n\\nYou'll hear them called a lot of things, including 'the relationship between this and that', but that's not what they are that's just what they can be used to understand or memorize. \\n\\nYou'll hear them called equations, and you'll eventually be shown all sorts of formulas for plotting them, and every year you stick with math classes you'll see a new way of calculating them, because there are so many ways, but that's not what they are. \\n\\nYou'll be told to remember a list of special angles that you can use to recreate them in various coordinate planes, but that's not what they are either. \\n\\nThey're just simple shapes. A pair of curves, one offset by 25% from the other but otherwise identical. Smooth simple curves that go on forever, because that's what we say they are.\\n\\nI could tell you some numbers, or some equations, but you'll see plenty of those in school and familiarizing yourself with and memorizing them is really pretty easy.\\n\\nThe hard part is understanding the idea that you can take these 2 shapes and build anything you can imagine out of them. The idea that every music recording and digital radio signal is made by using a computer to turn sound and video and data into combinations of these 2 very simple and very similar but crucially different curves.\\n\\nBut let's not start with that. That talk of radio waves and music signals from sin and cosine? Why, I didn't properly understand that until the 4th year of my bachelor's degree in electrical engineering, with a course specialization in digital signals and audio processing, and you're just heading towards the first steps of that wonderful journey and I bet you don't even know it. Because I didn't, and when I asked my teacher why we were learning this stuff back in high school he just sighed. \\n\\nOh, and before I continue writing about this thing I love, maybe I should answer your question. It would be the polite thing to do.\\n\\nI'll skip how your calculator adds and subtracts and divides and multiples and stores numbers and notices button presses, because those are long and difficult (but beautiful, to be sure) stories. But I will tell you this: there's a cheat sheet in your calculator, called a lookup table, a chunk of digital memory really, that has the answers for sin(0.01) and sin(0.02) and so on, so when you press the sin key on your calculator it checks that table. And if the input number is somewhere between 0.01 and 0.02, it takes the input number and the 2 nearest answers it has, and it runs a fairly simple interpolation equation which consists of adding and subtracting and multiplying and dividing with those 3 numbers and some constants like 1 and -3 and 5. I don't know which equation it uses, but if you cracked open your calculator, read the serial number off the microchip inside, googled it, and emailed the company who made the chip, they'd probably tell you and be delighted by your curiosity. \\n\\nIf you'd like to just see an equation that might be the one they use, take a look at some of the equations with the words 'sin(x)' next to them, and ignore any equations with fancy unfamiliar symbols. _URL_4_\\n\\nSo anyway, like I was saying, sine and cosine are just shapes. And that beings us to tangent, which is just sine divided by cosine. Had anyone mentioned yet that you can divide and multiply shapes? Because that's a thing you can do. If it's confusing, and it was for me at first, do some equation plotting exercises so that the idea gets more comfortable in your brain in time. It will. Watching YouTube math videos will also help.\\n\\nIf you can get that one down, then understanding that secant and cosecant and cotangent are just a flat line divided by cosine and sine and tangent (respectively) will make sense eventually too. \\n\\nAnd if all this is frustrating, and you wish that your teachers would just explain what these equations are used for, try to remember that your teachers and I were unable to understand that until we'd learned the basics by repetitive memorization, in much the same way that we had to start learning multiplication tables before we understood why we'd need them. And remember that people who find math easy from the start rarily develop the study skills to become brilliant, and those who became brilliant all had to struggle.\",\n",
       "    'To visualize trig functions of some angle, imagine that angle is the corner of a right triangle. Trig functions are a ratio of side length. And just remember this:\\n\\n**Soh Cah Toa**\\n\\nSine = opposite side/hypotenuse\\n\\nCosine = adjacent side/hypotenuse\\n\\nTangent = opposite side/adjacent side',\n",
       "    \"You haven't done trigonometry yet? What are you using these functions for? They appear in many contexts but I can't think of any that would be taught before trigonometry.\\n\\nAt the very basic level sine, cosine, and tangent correspond to relationships between an angle in a right angle triangle and the side lengths of the triangle. This actually lets you write down exact answers to the functions (e.g. sin(x) ) for certain values of x.\\n\\n > I just want to perfectly understand as much as possible what's happening when I throw these into the calculator. \\n\\nWhat happens when you type these into a calculator is *a lot* more complicated. I'm not sure if these functions have a special algorithm to compute them numerically, but my 'naive' approach would involve calculus (which is still quite a way away for you). \\n\\nSine and cosine correspond to the solutions of a certain 'initial value problem', which is a type of problem involving 'differential equations'. That is to say we can exploit known relationships of their derivatives and their values and rates of change at x=0 to figure out numerically their values.\\n\\nFor example for sin(x), we know that sin(0)=0, it is also know that the 'rate of change' of the sine function is 1 at 0, and it is known that sin(x) is a solution to this differential equation: d^2 /dx^2 (y)=-y . This and some theory tells us that sin(x) the unique solution of:\\n\\nd^2 /dx^2 (y)=-y ; y(0)=0 ; dy/dx (0)=1\\n\\nWhich can accurately, and efficiently be solved by a computer for any x using a number of different numerical methods. \\n\\nThis may sound overwhelming but it's rather straight forward when you have the background, the short answer is that figuring out exact values of sin(x) for a given x is a hard task in general and it takes a lot of work to get a computer to do that.\\n\\nI'd need to know more about your background and where you are currently at in your course work to give you an overview for how the functions are used (again, I feel the best intuition comes from trigonometry). I would encourage you to go to /r/learnmath as they specialize in explaining course material from grade school through grad school.\",\n",
       "    'Take a piece of paper and a straight edge.\\n\\nDraw a line as the horizon, and another line at an angle to it. \\n\\nThe length of that line is the length of the straight edge, and we\\'ll call that 1.\\n\\nSo there\\'s a few other measurements we have.  For instance, at the end of the line, it diverges from the horizon by a certain amount.   If it is a 30 degree angle that you\\'ve made, it diverges from the horizon by 1/2 the length of the ruler.  This is the sin.  \\n\\nSo if you have an angle that is 0 degrees, it will not diverge at all from the horizon, so sin(0) is 0.\\n\\nIf you have an angle that is 30 degrees you find that the end of that line is 0.5 times as long as your ruler away from the horizon. So sin(30 degrees) is 0.5\\n\\nIf you have an angle that is 90 degrees, it is going straight up, and so it diverges the same length as the ruler.  So sin(90 degrees) is 1. \\n\\nCosine is the same deal, except it is not measuring to the horizon, it\\'s measuring to a line perpendicular to the horizon.  Since this is essentially the same thing as sine, but in relation to a different axis, it\\'s called cosine.  So in the same way, if you have a line that is 0 degrees from the horizon, it\\'s going to be one ruler-length from the y-axis.  If it\\'s 60 degrees from the horizon, it\\'s going to be 0.5 ruler lengths from the y-axis, and if it\\'s on the y axis, it\\'s going to be 0 away.  So cos(0) = 1, cos(60 degrees) = 0.5, cos (90 degrees) = 0.\\n\\nSo what happens when you vary the length of the ruler? Those values are just ratios, so they don\\'t change.  So if you were to make a 30 degree line that was 2 rulers long, and you were to measure the distance to the horizon, you would see it was a distance of 1 ruler to the horizon.  In the same way, if you had one ruler twice as long, you would see the distance was one half that longer ruler.   I\\'m belaboring a simple point, but the ratio is going to be divided by the length of the line.  \\n\\nSo sin is the value of the distance to the horizon, proportional to the distance from the origin.  \\n\\nIf you were to draw the shortest line possible to the horizon from the end of your line, you would have a right-angle triangle. This is where the right angle triangles come from.  The reason sine is opposite over hypotenuse is because the \"opposite\" length is the distance to the horizon.  The \"hypotenuse\" length is the length of the ruler.  \\n\\nWhat you are really measuring is for a line at an angle of x, how far does it diverge from the horizon for every unit it goes away from the origin.\\n\\nFor cosine it\\'s a question of how far does it diverge from a line perpendicular to the horizon for every unit it moves from the origin. \\n\\nThe rest are all kind of secondary and have more to do with circles.\\n\\nTangent is a bit different.  It\\'s used less, and is often really just a composite of sine and cosine.  \\n\\nI\\'ll start with why it\\'s called a tangent.  If you have a circle, at any point along the circle you can draw a line to the center of the circle.  The line that is at a right angle to the line you drew is a tangent. \\n\\nSo if you take the line you drew, and use a compass to make a circle whose center is in the origin, and which touches the end of the line, we can use that to talk about the others.\\n\\nIf you draw a straight line that is tangential to your circle, touching it on the horizon, it will be perpendicular to the horizon.  If you extend the line that you drew until it meets that point on the tangent line, the distance to the horizon from where your angle meets that tangent line is the tangent.\\n\\nIf you think about what\\'s happening there, it\\'s very similar to the sine.  You\\'re getting the distance that it has diverged from the horizon, but instead of being relative to the length of the whole line that you extended to the tangent line, it is relative to the distance you first drew.  This is the same as the radius of the circle.\\n\\nSince these are all just ratios, as long as you scale them uniformly, they will stay the same.  So instead draw the same angle at one ruler length, and connect it to the horizon as a right angled triangle.  Then instead of drawing a circle that touches the end of your angle, draw it so that it touches the right angle formed.  That line you extended down is the tangent line we drew in the first example.  Like the first example it is relative to the distance from the origin to where the angle touches the circle.  Since that\\'s the same anywhere, because it\\'s a circle, the distance along the horizon works as well.\\n\\nSo on that triangle, we have the distance from the angle to the horizon, and then we have the distance along the horizon to where it intersects with the line we draw from the end of the angle.  The distance to the horizon in that case is the \"opposite\" length, and the radius of the circle that would be drawn will be the same as the \"adjacent\" length.  \\n\\nThis is why tangent is called tangent, and why it\\'s calculated as opposite over adjacent. \\n\\nSo then you have cotangent, which is essentially the same thing as tangent, but measures the length of a tangent line perpendicular to tangent.  For all the same reasons it\\'s going to be adjacent over opposite.   Just like sine and cosine it\\'s the same function, just compared to a different plane.\\n\\nSo then what is secant and cosecant? \\n\\nWell, when we first did our tangent example, we extended the line we drew for the angle up to the tangent line.  The secant is the length of the whole line if you were to attach it to the tangent.  \\n\\nSo how do we come up with that?  Well consider how we got the tangent.  Instead of using the hypotenuse for scaling like we did for sin and cos, we used the adjacent length to scale.\\n\\nFor secant we are doing the same thing.  We want to find the length of the line drawn to the tangent relative to one unit of measurement.   So we draw an angle that is one unit long, and turn it into a right triangle.  We draw a circle with the center on the origin and the edge of the circle on the point where the horizon touches the right angle.  Now secant is asking the question \"how many times longer than the radius of this circle is the distance to that tangent line?\"  But like tangent, since the radius of the circle is the same anywhere, if we know the adjacent distance it is the same.  The length of the whole line is the hypotenuse.  So we find the secant by dividing the hypotenuse length by the adjacent length.\\n\\nSecant happens to be the reciprocal of the cosine function, but the questions that secant asks have to do with distances to the x-axis.\\n\\nCosecant asks the same questions, but like all of its friends is doing so relative to the y-axis.  Again, it happens to be the reciprocal of the sin function, but that can be confusing.\\n\\n\\nIn short, \\n\\n* sin is the distance of an angle to the horizon\\n* tan is the length of a line segment tangential to a circle touching the horizon and a beam cast by the angle.\\n* secant is the length of the line segment required to intersect with that tangent line relative to the radius of the circle that line is tangential to. \\n* cos, cot, csc are all the same functions, but they are relative to the y-axis rather than the x-axis. \\n* Also, SOHCAHTOA.  That will help you remember how, but not why.',\n",
       "    \"I think an intuitive way is to imagine a simple 2d game (by the way the same is also completely true of 3d but it needlessly complicates it for this example). Imagine you have a ship at the center of a map. We'll consider this point to be 0,0. The ship can rotate and change its heading which we'll consider as being in degrees, and it can forward/backwards along its current heading. So the question is when the ship decides to go forward 1 unit, how do we know how much its x and y coordinates have changed? I mean if its facing due east then we know its x changes +1 and the y changes 0. Similarly if its facing due north then its y changes 1 and its x changes 0. What if its facing at a 35 degree angle?\\n\\nLike others have said this is where we can understand and actually use sin/cos. It's oddly enough incredibly simple. x = cosine. y = sine. If your ship is facing at a 35 degree angle then the factor of the change in x is cos(35) and similarly the factor of the change in y is sin(35). \\n\\nxFactor = cos(35) = 0.81915204428\\nyFactor = sin(35) = 0.57357643635\\n\\nNow let's say our ship has a velocity of 2. We now have enough to calculate its new position!\\n\\nxChange = xFactor * velocity = 0.81915204428 * 2 = 1.63830408856\\nyChange = yFactor * velocity = 0.57357643635 * 2 = 1.1471528727\\n\\nSo if our ship started at 0,0 with a velocity of 2 on a heading of 35 degrees, it's new position would simply be: 1.64, 1.15. Okay, perhaps you're thinking that's a lot of movement when it was only supposed to go 2 units. Well we can prove this is correct using the pythagorean theorem as well! Draw a right triangle with a base of 1.64, a height of 1.15 and let's get the distance it traveled on the top - the hypotenuse.\\n\\na^2 + b^2 = c^2. \\n1.64^2 + 1.15^2 = c^2\\n4 = c^2\\nc = 2\\n\\nWe traveled exactly 2 units.\\n\\nTangent is just a shortcut that is useful for a lot of neat things. Take your yFactor up above and divide it by your xFactor. That's tangent. In this case that'd be 0.57357643635/0.81915204428 = 0.70020753821 which is indeed the tangent of 35 degrees!\\n\\nGoing back the initial topic. If we're going due east then we know our ship is only going to move along the east. So xFactor = 1, yFactor = 0. As you can verify cos(0) = 1, sin(0) = 0.\\n\\nHopefully if you think about this then you could instantly and intuitively determine the sin/cos of 0,90,180 and 270 degrees. And from there you could also even get the tangent! With a little bit of thinking you should even be able to ballpark any sin/cos/tan, something the vast majority of people ~~cannot~~ *do not know how to* do!\",\n",
       "    'This is a physical understanding of the functions, but sine, cosine and tangent are used far beyond cartesian geometry.\\n\\nImagine that you have a straight line segment, and arrange a grid over top of it so that you have the origin at one end of the line segment (orientation/rotation is unimportant). \\n\\nThe cosine tells you what fraction of the total length is in the horizontal direction.\\n\\nThe sine tells you what fraction of the total length is in the vertical direction.\\n\\nThe tangent tells you the relationship between the vertical and horizontal components. (how \"up\" is the other end of the line segment relative to how far \"over\" it is)\\n\\n\\nIt is very difficult to give a person an intuitive understanding of sine/cosine/tangent without knowing what you do and do not understand about it.\\n\\nFor example, I could tell you about sequences and series. One of the simplest series is:\\n\\nf(x) = 1+x+x^2 / 2! + x^3 /3! +....\\n\\nCosine and Sine are really just the even and odd powers of this series, respectively, when x is a purely imaginary number. But I am guessing that this is pretty far beyond where you are at. It just serves to explain how difficult it is to explain this issue, considering that there are so many different levels with which to explain it.',\n",
       "    \"Get a textbook on precalculus.  It will help more than what everyone here is saying.  What I don't understand is why you're even using them when you haven't taken trig yet.  It is its own subset of math like Algebra.  Like so:\\n\\nArithmetic - >  Algebra - >  Algebra 2 - >  Geometry - >  Trigonometry/Precalculus - >  Calculus 1 (derivatives) - >  Calculus 2 (integrations - >  Calculus 3 (multivariable) - >  Differential Equations\\n\\nConsidering you want to understand I'd assume you would want to do something math related.  This is the path for engineering but for a math major the same base applies.\\n\\nCheck out Khan Academy and the MIT open courseware as well.\",\n",
       "    'Think of a unit circle (circle of radius 1, centered at the origin).   Imagine of a hand (like hand on a clock face) that connects the center to a point on the circle.\\n\\n* Cosine of the angle that the hand makes with the x-axis is the shadow of the stick on the x-axis if the light were shining down the y-axis.\\n* Sine of the angle that the hand makes with the x-axis is the shadow of the stick on the y-axis if light where shining along the x-axis.\\n\\nNow imagine slowly rotating the hand to change the angle and think about how the two shadow will change.\\n\\nNow suppose the hand is also a freaking light saber.  Also suppose there is a vertical stick (parallel to y-axis) that is tangent to the circle at x=1, where the circle cross the x-axis.\\n\\n* Tangent of the angle the hand makes with the x-axis is the length of the stick that gets cut by the light saber.\\n* Cotangent is similar, except for a horizontal stick that is tangent to the circle at y=1, where the circle cross the y-axis.',\n",
       "    'The best way for me to remember their components is SOHCAHTOA sin(opposite/hypotenuse) cos(adjacent/hypotenuse) tan(opposite/adjacent).\\n\\nNow if you move to graphing (x,y) = (cos(theta), sin(theta)) then you have all of the points. Best way to thing about it is as in quadrants so from 0 - pi/2 you have (0, pi/6, pi/4, pi/3, pi/2). If you look at the points pi/2 is (0,1) and 0 is (1,0). Now you know the other three points at 1/2, root(2)/2, and root(3)/2 so just think about where the line would correspond on a circle and what should have the bigger value x or y. \\n\\nThen you have sin^2(theta) + cos^2(theta) = 1 and we know that tan(theta) = sin/cos. so from that equation we can solve for csc(theta), sec(theta) and cot(theta). The best was for me to remember what csc and sec is csc has a \"c\" so it isn\\'t cos and sec has an \"s\" so it isn\\'t sin.',\n",
       "    \"Everyone here is making it a lot more complex than it needs to me. \\nThe trig functions are actually very simple. \\n\\nWhen you have a right triangle, all of your three angles will add up to 180 degrees. \\nIt has been proven that, with a specific angle, there will be a consistent ratio of two side lengths. \\nHence where soh cah toa pops in. (Opposite over hypotenuse, adjacent over hypotenuse, opposite over adjacent). \\n\\nTherefore, if you know the angle, and know one side, you can find all three triangle lengths based on this table of ratios, regardless of the actual lengths. They can be millions of miles, and they can be nanometers. \\n\\nThat's it. It gets expended upon in unit circles, and used in calculus and differential equations, but understanding this basic process is important to understanding the rest.\",\n",
       "    \"I'd like to give a go at a simple and intuitive answer.\\n\\nPicture a force acting in an xy plane.  The cosine represents the percent of that force acting in the x directon.  Sine represents the percent acting in the y direction.\\n\\nSo, if you have 100 lbs at 15 degrees that means you have sin (15), or .258, or 25.8 lbs acting in the y.  You have cos (15), or .965, or 96.5 lbs acting along x.\\n\\nHope this helps.\\n\\nP.S.  Why do the percentages not add up to 1?  The resultant is the square root of the individual components squared, so square .258 and .965, add them and take the square root and you have 1.\",\n",
       "    'Here is a way to remember the equations:\\n\\n\\nOscar Had A Hard On And Sally Could Tell. ( first letter in each word)\\n\\n\\nFirst write down the two letters in groups of two:\\n\\nOH= (oscar had)\\n\\nAH=(A Hard)\\n\\nOA=(On And)\\n\\nThen write down the last three letters next to each group of two.\\n\\nS (Sally)\\n\\nC (Could)\\n\\nT (Tell)\\n\\n\\nin the end it would look like this:\\n\\nO/H=S\\n\\nA/H=C\\n\\nO/A=T\\n\\nOpposite over Hypotenuse = Sine\\n\\nAdjacent over Hypotenuse = Cosine\\n\\nOpposite over Adjacent = Tangent\\n\\nThank  my ninth grade Trig teacher for that one.  He exchanged HAT for HARD, but eluded to the dirty word and our ninth grade juvenile minds did the rest.',\n",
       "    \"Do you have a point on a circle? The *main thing to know* is that Cosine is the X coordinate and Sine is the Y coordinate.\\n\\nThere is a scale factor in there, and the angle is in radians, bit if you remember what they are you're most of the way there.\",\n",
       "    \"Hasn't anyone ever stumbled upon [_URL_6_](_URL_5_) by Kalid Azad??\\n\\nHere's his article on [Intuitive Trigonometry](_URL_5_/articles/intuitive-trigonometry).\\n\\nCheck out the site, He has got tons of other stuff like this...\"],\n",
       "   'score': [584,\n",
       "    193,\n",
       "    191,\n",
       "    42,\n",
       "    18,\n",
       "    15,\n",
       "    11,\n",
       "    8,\n",
       "    7,\n",
       "    6,\n",
       "    6,\n",
       "    4,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2]},\n",
       "  {'a_id': ['c8knyk4', 'c8kphpb', 'c8klvyd', 'c8kmuxt'],\n",
       "   'text': ['[This wiki page is very, very relevant.](_URL_0_) The thought you had is very similar to an important thought experiment that was at the heart of the development of special relativity.',\n",
       "    '[Yes!  ](_URL_1_)  This seems to be exactly the situation you are describing.\\n\\nThey drop aluminium and copper tubes down through an extremely strong magnet.',\n",
       "    \"I wish I could find the clip, but a magic revealed via physics type show had a metalic cannon ball drop down a tube while his hand was cuffed to a table beneath, they dropped it once to show the damage it would do, when they did the 2nd drop with his hand under the dropping ball, he got an extra few moment because the tube was magnetized and thus slowed the ball down.  \\n\\nThe same episode imploded a sealed train tanker. \\n\\n\\nThe show was Breaking magic on Discovery Channel.  Here is the portion at 14:00 but it's in [Italian](_URL_2_)\",\n",
       "    \"Sort of, yes. However, the eddy currents are due to a *change* in the strength of the magnetic field. Inside a fairly long tube, the magnetic fields will be nearly constant, so the copper won't continue to generate eddy currents. Those will only happen near the opening and exit of the tube. \\n\\nThe magnet generates currents in the tube the entire way down since different parts of the copper are exposed to the magnetic field at different times (so the copper experiences a changing magnetic flux). But the copper in the tube will for most of the tube experience a constant flux, so there won't be an induced field. At the beginning and end, however, the field will be non-constant, so that would slow the copper piece down.\"],\n",
       "   'score': [6, 6, 5, 2]},\n",
       "  {'a_id': ['e4j02cf', 'e4jcydl', 'e4j8usk'],\n",
       "   'text': ['The del operator shows up in the Laplacian, which is in the kinetic energy term, when the Schrodinger equation is written in the position basis. \\n\\n∇^(2) is a differential operator, equal to (d/dx)^(2) + (d/dy)^(2) + (d/dz)^(2), in Cartesian coordinates (the derivatives are partial derivatives).\\n\\n-~~h~~^(2)∇^(2)/2m is the kinetic energy operator in the position basis.',\n",
       "    'Good mathematical answers so far, but no intuitive ones.  Del (aka the Laplacian) measures the *curvature* of a 2- or 3-d function.  So for example, if your function is the height of the land surface, the top of a hill has a negative \"del\", the bottom of a lake has a positive \"del\".\\n\\nIn both 2- and 3-d, local minima of a function are found in regions of positive Laplacian, local maxima in regions of negative Laplacian.  (This may seem backwards, but it\\'s to do with the calculus definition of the operator.)\\n\\nIn the Schroedinger equation, the presence of the \"del\" indicates that the curvature, maxima and minima of the wavefunction are related to the energy of the particle.',\n",
       "    \"Usually, in N-dimensional calculus, the del operator means the vector (d/dx1, d/dx2, ..., d/dxN), where xi is the i'th coordinate. So in 3D, it is (d/dx, d/dy, d/dz). Applied to a scalar function f(x), it is ∇ f = (df/dx1, df/dx2, ... , df/dxN).\\n\\nIn quantum mechanics, it appears in the momentum operator, p = -i * hbar * ∇, in close analogy to the energy operator E = i * hbar * d/dt. When applied to a complex plane wave exp(i * (kx - ωt)), they return Planck's relation E = hbar * ω and deBroglie's relation p = hbar * k.\"],\n",
       "   'score': [19, 10, 5]}],\n",
       " 'title_urls': [{'url': []},\n",
       "  {'url': []},\n",
       "  {'url': []},\n",
       "  {'url': []},\n",
       "  {'url': []}],\n",
       " 'selftext_urls': [{'url': []},\n",
       "  {'url': []},\n",
       "  {'url': []},\n",
       "  {'url': []},\n",
       "  {'url': []}],\n",
       " 'answers_urls': [{'url': ['http://en.wikipedia.org/wiki/Cardiac_muscle',\n",
       "    'http://en.wikipedia.org/wiki/Smooth_muscle_tissue']},\n",
       "  {'url': ['http://www.infoworld.com/article/2612729/cringely/what-s-on-tap-at-the-nsa--google-s-and-yahoo-s-private-fiber-backbones.html',\n",
       "    'http://research.dyn.com/2009/02/the-flap-heard-around-the-world/',\n",
       "    'http://research.dyn.com/2009/02/longer-is-not-better/',\n",
       "    'https://en.wikipedia.org/wiki/MAE-East',\n",
       "    'https://en.wikipedia.org/wiki/List_of_Internet_exchange_points_by_size',\n",
       "    'https://en.wikipedia.org/wiki/Internet_exchange_point',\n",
       "    'http://www.amazon.com/Tubes-A-Journey-Center-Internet/dp/0061994952',\n",
       "    'http://www.enterprisenetworkingplanet.com/netsp/article.php/3615896/Networking-101-Understanding-BGP-Routing.htm',\n",
       "    'google.com',\n",
       "    'https://en.wikipedia.org/wiki/Room_641A',\n",
       "    'http://www.google.com/*',\n",
       "    'www.google.com/',\n",
       "    'www.pornhub.com',\n",
       "    'google.com']},\n",
       "  {'url': ['https://en.wikipedia.org/wiki/Unit_circle',\n",
       "    'https://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Circle-trig6.svg/500px-Circle-trig6.svg.png',\n",
       "    'http://upload.wikimedia.org/wikipedia/commons/3/3b/Circle_cos_sin.gif',\n",
       "    'http://upload.wikimedia.org/wikipedia/commons/e/ee/Tan_drawing_process.gif',\n",
       "    'http://en.m.wikipedia.org/wiki/Taylor_series',\n",
       "    'http://betterexplained.com',\n",
       "    'BetterExplained.com',\n",
       "    'http://betterexplained.com/articles/intuitive-trigonometry']},\n",
       "  {'url': ['http://en.wikipedia.org/wiki/Moving_magnet_and_conductor_problem',\n",
       "    'http://www.youtube.com/watch?v=QGytW_C6hR8#t=6m19s',\n",
       "    'https://www.youtube.com/watch?v=b2or6CuHsyg']},\n",
       "  {'url': []}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test_asks'][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ds = pd.DataFrame([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>document</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>answers</th>\n",
       "      <th>title_urls</th>\n",
       "      <th>selftext_urls</th>\n",
       "      <th>answers_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1xa1l8</td>\n",
       "      <td>If the heart is just a muscle, why can't I vol...</td>\n",
       "      <td>Oftentimes, when when I focus on my heartbeat,...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['cf9gyt1', 'cf9h410', 'cf9i6b2'], 't...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://en.wikipedia.org/wiki/Cardiac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3ko13p</td>\n",
       "      <td>In the latest Avengers movie, there is a \"Nexu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['cuz3k5a', 'cuz2ili', 'cuz3zwf', 'cu...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://www.infoworld.com/article/261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2jy57p</td>\n",
       "      <td>Can somebody give me an intuitive understandin...</td>\n",
       "      <td>I use them all the time for equations but they...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['clg9vcq', 'clga65f', 'clga5ty', 'cl...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['https://en.wikipedia.org/wiki/Unit_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1943xl</td>\n",
       "      <td>I've seen a magnet being dropped down a copper...</td>\n",
       "      <td>If you had a magnetic tube, and dropped a piec...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['c8knyk4', 'c8kphpb', 'c8klvyd', 'c8...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://en.wikipedia.org/wiki/Moving_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98va8l</td>\n",
       "      <td>What is the del operator in the Schrodinger eq...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['e4j02cf', 'e4jcydl', 'e4j8usk'], 't...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>3fbqr1</td>\n",
       "      <td>Is it possible to accurately predict the resul...</td>\n",
       "      <td>This is probably a really basic chemistry ques...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['ctoqy36', 'ctonyz7'], 'text': ['You...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['https://en.wikipedia.org/wiki/Chemic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>2t0vxd</td>\n",
       "      <td>Is the light clock model wrong?</td>\n",
       "      <td>Learning special relativity, teachers like to ...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['cnuqju4'], 'text': ['The clock mode...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://galileoandeinstein.physics.vi...</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>w74y9</td>\n",
       "      <td>What animal does this belong to?</td>\n",
       "      <td>_URL_0_\\n\\nI found this spine the other day an...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['c5auwkc', 'c5aua11'], 'text': ['The...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://imgur.com/a/FRVMv#0']}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>9r6yq1</td>\n",
       "      <td>Is fluid mechanics and vector analysis applica...</td>\n",
       "      <td>Just curious if there is any overlap into biol...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['e8ifhna'], 'text': ['Momentum and e...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>pgkgi</td>\n",
       "      <td>Are there any limits to what science can explain?</td>\n",
       "      <td>Are there any questions that science cannot an...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['c3p711s', 'c3p6x3c', 'c3p78gv', 'c3...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['https://en.wikipedia.org/wiki/Proble...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4462 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        q_id                                              title  \\\n",
       "0     1xa1l8  If the heart is just a muscle, why can't I vol...   \n",
       "1     3ko13p  In the latest Avengers movie, there is a \"Nexu...   \n",
       "2     2jy57p  Can somebody give me an intuitive understandin...   \n",
       "3     1943xl  I've seen a magnet being dropped down a copper...   \n",
       "4     98va8l  What is the del operator in the Schrodinger eq...   \n",
       "...      ...                                                ...   \n",
       "4457  3fbqr1  Is it possible to accurately predict the resul...   \n",
       "4458  2t0vxd                    Is the light clock model wrong?   \n",
       "4459   w74y9                   What animal does this belong to?   \n",
       "4460  9r6yq1  Is fluid mechanics and vector analysis applica...   \n",
       "4461   pgkgi  Are there any limits to what science can explain?   \n",
       "\n",
       "                                               selftext document   subreddit  \\\n",
       "0     Oftentimes, when when I focus on my heartbeat,...           askscience   \n",
       "1                                                                 askscience   \n",
       "2     I use them all the time for equations but they...           askscience   \n",
       "3     If you had a magnetic tube, and dropped a piec...           askscience   \n",
       "4                                                                 askscience   \n",
       "...                                                 ...      ...         ...   \n",
       "4457  This is probably a really basic chemistry ques...           askscience   \n",
       "4458  Learning special relativity, teachers like to ...           askscience   \n",
       "4459  _URL_0_\\n\\nI found this spine the other day an...           askscience   \n",
       "4460  Just curious if there is any overlap into biol...           askscience   \n",
       "4461  Are there any questions that science cannot an...           askscience   \n",
       "\n",
       "                                                answers   title_urls  \\\n",
       "0     {'a_id': ['cf9gyt1', 'cf9h410', 'cf9i6b2'], 't...  {'url': []}   \n",
       "1     {'a_id': ['cuz3k5a', 'cuz2ili', 'cuz3zwf', 'cu...  {'url': []}   \n",
       "2     {'a_id': ['clg9vcq', 'clga65f', 'clga5ty', 'cl...  {'url': []}   \n",
       "3     {'a_id': ['c8knyk4', 'c8kphpb', 'c8klvyd', 'c8...  {'url': []}   \n",
       "4     {'a_id': ['e4j02cf', 'e4jcydl', 'e4j8usk'], 't...  {'url': []}   \n",
       "...                                                 ...          ...   \n",
       "4457  {'a_id': ['ctoqy36', 'ctonyz7'], 'text': ['You...  {'url': []}   \n",
       "4458  {'a_id': ['cnuqju4'], 'text': ['The clock mode...  {'url': []}   \n",
       "4459  {'a_id': ['c5auwkc', 'c5aua11'], 'text': ['The...  {'url': []}   \n",
       "4460  {'a_id': ['e8ifhna'], 'text': ['Momentum and e...  {'url': []}   \n",
       "4461  {'a_id': ['c3p711s', 'c3p6x3c', 'c3p78gv', 'c3...  {'url': []}   \n",
       "\n",
       "                                          selftext_urls  \\\n",
       "0                                           {'url': []}   \n",
       "1                                           {'url': []}   \n",
       "2                                           {'url': []}   \n",
       "3                                           {'url': []}   \n",
       "4                                           {'url': []}   \n",
       "...                                                 ...   \n",
       "4457                                        {'url': []}   \n",
       "4458  {'url': ['http://galileoandeinstein.physics.vi...   \n",
       "4459            {'url': ['http://imgur.com/a/FRVMv#0']}   \n",
       "4460                                        {'url': []}   \n",
       "4461                                        {'url': []}   \n",
       "\n",
       "                                           answers_urls  \n",
       "0     {'url': ['http://en.wikipedia.org/wiki/Cardiac...  \n",
       "1     {'url': ['http://www.infoworld.com/article/261...  \n",
       "2     {'url': ['https://en.wikipedia.org/wiki/Unit_c...  \n",
       "3     {'url': ['http://en.wikipedia.org/wiki/Moving_...  \n",
       "4                                           {'url': []}  \n",
       "...                                                 ...  \n",
       "4457  {'url': ['https://en.wikipedia.org/wiki/Chemic...  \n",
       "4458                                        {'url': []}  \n",
       "4459                                        {'url': []}  \n",
       "4460                                        {'url': []}  \n",
       "4461  {'url': ['https://en.wikipedia.org/wiki/Proble...  \n",
       "\n",
       "[4462 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_ds = dataset['test_asks'].to_pandas()\n",
    "temp_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
       "    num_rows: 4462\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test_asks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>document</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>answers</th>\n",
       "      <th>title_urls</th>\n",
       "      <th>selftext_urls</th>\n",
       "      <th>answers_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1xa1l8</td>\n",
       "      <td>If the heart is just a muscle, why can't I vol...</td>\n",
       "      <td>Oftentimes, when when I focus on my heartbeat,...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['cf9gyt1', 'cf9h410', 'cf9i6b2'], 't...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://en.wikipedia.org/wiki/Cardiac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3ko13p</td>\n",
       "      <td>In the latest Avengers movie, there is a \"Nexu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['cuz3k5a', 'cuz2ili', 'cuz3zwf', 'cu...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://www.infoworld.com/article/261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2jy57p</td>\n",
       "      <td>Can somebody give me an intuitive understandin...</td>\n",
       "      <td>I use them all the time for equations but they...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['clg9vcq', 'clga65f', 'clga5ty', 'cl...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['https://en.wikipedia.org/wiki/Unit_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1943xl</td>\n",
       "      <td>I've seen a magnet being dropped down a copper...</td>\n",
       "      <td>If you had a magnetic tube, and dropped a piec...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['c8knyk4', 'c8kphpb', 'c8klvyd', 'c8...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://en.wikipedia.org/wiki/Moving_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98va8l</td>\n",
       "      <td>What is the del operator in the Schrodinger eq...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['e4j02cf', 'e4jcydl', 'e4j8usk'], 't...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136235</th>\n",
       "      <td>c3yf3z</td>\n",
       "      <td>How much carbon dioxide is stored in leaves, t...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['erubgvz', 'ervj703', 'eru6zhw'], 't...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['https://cdiac.ess-dive.lbl.gov/pns/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136236</th>\n",
       "      <td>q7db5</td>\n",
       "      <td>Why does cyanide kill you so quickly?</td>\n",
       "      <td>Hitler and many other German officials committ...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['c3vc32o', 'c3vgpwl', 'c3vbhte', 'c3...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://en.wikipedia.org/wiki/Death_o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136237</th>\n",
       "      <td>163s6a</td>\n",
       "      <td>How does cyanide kill you?</td>\n",
       "      <td>I've been researching for a school paper but c...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['c7sgpd7', 'c7sginx'], 'text': ['Cya...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://www.jbc.org/content/269/39/24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136238</th>\n",
       "      <td>itwn2</td>\n",
       "      <td>Why do LCD monitors have fixed refresh rates?</td>\n",
       "      <td>Why wouldn't an lcd monitor just be able to dr...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['c26mrg1', 'c26nnpw'], 'text': ['Thi...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136239</th>\n",
       "      <td>1bkatn</td>\n",
       "      <td>Why do modern LCD monitors stick to the refres...</td>\n",
       "      <td>As far as I know, the only part that could ind...</td>\n",
       "      <td></td>\n",
       "      <td>askscience</td>\n",
       "      <td>{'a_id': ['c97hw8d', 'c97k9js'], 'text': ['_UR...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://m.cnet.com/news/what-is-refre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136240 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_id                                              title  \\\n",
       "0       1xa1l8  If the heart is just a muscle, why can't I vol...   \n",
       "1       3ko13p  In the latest Avengers movie, there is a \"Nexu...   \n",
       "2       2jy57p  Can somebody give me an intuitive understandin...   \n",
       "3       1943xl  I've seen a magnet being dropped down a copper...   \n",
       "4       98va8l  What is the del operator in the Schrodinger eq...   \n",
       "...        ...                                                ...   \n",
       "136235  c3yf3z  How much carbon dioxide is stored in leaves, t...   \n",
       "136236   q7db5              Why does cyanide kill you so quickly?   \n",
       "136237  163s6a                         How does cyanide kill you?   \n",
       "136238   itwn2      Why do LCD monitors have fixed refresh rates?   \n",
       "136239  1bkatn  Why do modern LCD monitors stick to the refres...   \n",
       "\n",
       "                                                 selftext document  \\\n",
       "0       Oftentimes, when when I focus on my heartbeat,...            \n",
       "1                                                                    \n",
       "2       I use them all the time for equations but they...            \n",
       "3       If you had a magnetic tube, and dropped a piec...            \n",
       "4                                                                    \n",
       "...                                                   ...      ...   \n",
       "136235                                                               \n",
       "136236  Hitler and many other German officials committ...            \n",
       "136237  I've been researching for a school paper but c...            \n",
       "136238  Why wouldn't an lcd monitor just be able to dr...            \n",
       "136239  As far as I know, the only part that could ind...            \n",
       "\n",
       "         subreddit                                            answers  \\\n",
       "0       askscience  {'a_id': ['cf9gyt1', 'cf9h410', 'cf9i6b2'], 't...   \n",
       "1       askscience  {'a_id': ['cuz3k5a', 'cuz2ili', 'cuz3zwf', 'cu...   \n",
       "2       askscience  {'a_id': ['clg9vcq', 'clga65f', 'clga5ty', 'cl...   \n",
       "3       askscience  {'a_id': ['c8knyk4', 'c8kphpb', 'c8klvyd', 'c8...   \n",
       "4       askscience  {'a_id': ['e4j02cf', 'e4jcydl', 'e4j8usk'], 't...   \n",
       "...            ...                                                ...   \n",
       "136235  askscience  {'a_id': ['erubgvz', 'ervj703', 'eru6zhw'], 't...   \n",
       "136236  askscience  {'a_id': ['c3vc32o', 'c3vgpwl', 'c3vbhte', 'c3...   \n",
       "136237  askscience  {'a_id': ['c7sgpd7', 'c7sginx'], 'text': ['Cya...   \n",
       "136238  askscience  {'a_id': ['c26mrg1', 'c26nnpw'], 'text': ['Thi...   \n",
       "136239  askscience  {'a_id': ['c97hw8d', 'c97k9js'], 'text': ['_UR...   \n",
       "\n",
       "         title_urls selftext_urls  \\\n",
       "0       {'url': []}   {'url': []}   \n",
       "1       {'url': []}   {'url': []}   \n",
       "2       {'url': []}   {'url': []}   \n",
       "3       {'url': []}   {'url': []}   \n",
       "4       {'url': []}   {'url': []}   \n",
       "...             ...           ...   \n",
       "136235  {'url': []}   {'url': []}   \n",
       "136236  {'url': []}   {'url': []}   \n",
       "136237  {'url': []}   {'url': []}   \n",
       "136238  {'url': []}   {'url': []}   \n",
       "136239  {'url': []}   {'url': []}   \n",
       "\n",
       "                                             answers_urls  \n",
       "0       {'url': ['http://en.wikipedia.org/wiki/Cardiac...  \n",
       "1       {'url': ['http://www.infoworld.com/article/261...  \n",
       "2       {'url': ['https://en.wikipedia.org/wiki/Unit_c...  \n",
       "3       {'url': ['http://en.wikipedia.org/wiki/Moving_...  \n",
       "4                                             {'url': []}  \n",
       "...                                                   ...  \n",
       "136235  {'url': ['https://cdiac.ess-dive.lbl.gov/pns/c...  \n",
       "136236  {'url': ['http://en.wikipedia.org/wiki/Death_o...  \n",
       "136237  {'url': ['http://www.jbc.org/content/269/39/24...  \n",
       "136238                                        {'url': []}  \n",
       "136239  {'url': ['http://m.cnet.com/news/what-is-refre...  \n",
       "\n",
       "[136240 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_ds = pd.concat([temp_ds, dataset['train_asks'].to_pandas()], ignore_index=True)\n",
    "temp_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>document</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>answers</th>\n",
       "      <th>title_urls</th>\n",
       "      <th>selftext_urls</th>\n",
       "      <th>answers_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1oy5tc</td>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2lojul</td>\n",
       "      <td>Why are different tiers (regular &lt; mid &lt; premi...</td>\n",
       "      <td>I've noticed that the difference in price betw...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['clwqgxl', 'clwqpjq', 'clwuh3s'], 't...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8v5e3s</td>\n",
       "      <td>Stars and Visibility</td>\n",
       "      <td>Why do stars in the night's sky seem to disapp...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['e1kpw6u'], 'text': ['It's a quirk o...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1v3wij</td>\n",
       "      <td>How do we know all the money the government is...</td>\n",
       "      <td>We hear about these large billion dollar bank ...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['ceohakd', 'ceoikhs', 'ceoji15', 'ce...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://dealbook.nytimes.com/2014/01/...</td>\n",
       "      <td>{'url': ['http://www.reuters.com/article/2013/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2jlp6f</td>\n",
       "      <td>What are good and bad sides of manual and auto...</td>\n",
       "      <td>Please consider I'm not a driver. Automatic se...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['clcur3j'], 'text': ['Automatics wei...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558664</th>\n",
       "      <td>1cwijw</td>\n",
       "      <td>What was the biggest man-made loss of life in ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['c9kne6c'], 'text': ['The largest I ...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558665</th>\n",
       "      <td>8fucgx</td>\n",
       "      <td>Hi, I was hoping that someone would be able to...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['dy6lps1'], 'text': ['In Western Eur...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558666</th>\n",
       "      <td>u4oom</td>\n",
       "      <td>What was the US Government's reaction to the D...</td>\n",
       "      <td>Obviously now there is an infrastructure in pl...</td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['c4sasnw'], 'text': ['The New Dealer...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558667</th>\n",
       "      <td>bh9auu</td>\n",
       "      <td>What did America do after the dust bowl</td>\n",
       "      <td>Today I was learning about the dust bowl, whic...</td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['elrx4pm'], 'text': ['Agricultural p...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558668</th>\n",
       "      <td>af1ilk</td>\n",
       "      <td>Do animals have historical agency?</td>\n",
       "      <td>Can we define cod, cattle, or capybaras as act...</td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['eduwsnl'], 'text': ['Timothy Mitche...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558669 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_id                                              title  \\\n",
       "0       1oy5tc  in football whats the point of wasting the fir...   \n",
       "1       2lojul  Why are different tiers (regular < mid < premi...   \n",
       "2       8v5e3s                               Stars and Visibility   \n",
       "3       1v3wij  How do we know all the money the government is...   \n",
       "4       2jlp6f  What are good and bad sides of manual and auto...   \n",
       "...        ...                                                ...   \n",
       "558664  1cwijw  What was the biggest man-made loss of life in ...   \n",
       "558665  8fucgx  Hi, I was hoping that someone would be able to...   \n",
       "558666   u4oom  What was the US Government's reaction to the D...   \n",
       "558667  bh9auu            What did America do after the dust bowl   \n",
       "558668  af1ilk                 Do animals have historical agency?   \n",
       "\n",
       "                                                 selftext document  \\\n",
       "0                                                                    \n",
       "1       I've noticed that the difference in price betw...            \n",
       "2       Why do stars in the night's sky seem to disapp...            \n",
       "3       We hear about these large billion dollar bank ...            \n",
       "4       Please consider I'm not a driver. Automatic se...            \n",
       "...                                                   ...      ...   \n",
       "558664                                                               \n",
       "558665                                                               \n",
       "558666  Obviously now there is an infrastructure in pl...            \n",
       "558667  Today I was learning about the dust bowl, whic...            \n",
       "558668  Can we define cod, cattle, or capybaras as act...            \n",
       "\n",
       "                subreddit                                            answers  \\\n",
       "0       explainlikeimfive  {'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...   \n",
       "1       explainlikeimfive  {'a_id': ['clwqgxl', 'clwqpjq', 'clwuh3s'], 't...   \n",
       "2       explainlikeimfive  {'a_id': ['e1kpw6u'], 'text': ['It's a quirk o...   \n",
       "3       explainlikeimfive  {'a_id': ['ceohakd', 'ceoikhs', 'ceoji15', 'ce...   \n",
       "4       explainlikeimfive  {'a_id': ['clcur3j'], 'text': ['Automatics wei...   \n",
       "...                   ...                                                ...   \n",
       "558664      AskHistorians  {'a_id': ['c9kne6c'], 'text': ['The largest I ...   \n",
       "558665      AskHistorians  {'a_id': ['dy6lps1'], 'text': ['In Western Eur...   \n",
       "558666      AskHistorians  {'a_id': ['c4sasnw'], 'text': ['The New Dealer...   \n",
       "558667      AskHistorians  {'a_id': ['elrx4pm'], 'text': ['Agricultural p...   \n",
       "558668      AskHistorians  {'a_id': ['eduwsnl'], 'text': ['Timothy Mitche...   \n",
       "\n",
       "         title_urls                                      selftext_urls  \\\n",
       "0       {'url': []}                                        {'url': []}   \n",
       "1       {'url': []}                                        {'url': []}   \n",
       "2       {'url': []}                                        {'url': []}   \n",
       "3       {'url': []}  {'url': ['http://dealbook.nytimes.com/2014/01/...   \n",
       "4       {'url': []}                                        {'url': []}   \n",
       "...             ...                                                ...   \n",
       "558664  {'url': []}                                        {'url': []}   \n",
       "558665  {'url': []}                                        {'url': []}   \n",
       "558666  {'url': []}                                        {'url': []}   \n",
       "558667  {'url': []}                                        {'url': []}   \n",
       "558668  {'url': []}                                        {'url': []}   \n",
       "\n",
       "                                             answers_urls  \n",
       "0                                             {'url': []}  \n",
       "1                                             {'url': []}  \n",
       "2                                             {'url': []}  \n",
       "3       {'url': ['http://www.reuters.com/article/2013/...  \n",
       "4                                             {'url': []}  \n",
       "...                                                   ...  \n",
       "558664                                        {'url': []}  \n",
       "558665                                        {'url': []}  \n",
       "558666                                        {'url': []}  \n",
       "558667                                        {'url': []}  \n",
       "558668                                        {'url': []}  \n",
       "\n",
       "[558669 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([])\n",
    "\n",
    "for i in list (dataset.keys() ):\n",
    "  df = pd.concat([df, dataset[i].to_pandas()], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lets check if the length of the dataframe is equal to the sum of the length of the individual datasets\n",
    "len(df) == sum( [len(dataset[i]) for i in list (dataset.keys())] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_id': array(['ccwtgnz', 'ccwtmho', 'ccwt946', 'ccwvj0u'], dtype=object),\n",
       " 'text': array([\"Keep the defense honest, get a feel for the pass rush, open up the passing game. An offense that's too one dimensional will fail. And those rushes up the middle can be busted wide open sometimes for big yardage.\",\n",
       "        \"If you throw the ball all the time, then the defense will adapt to always cover for a pass.  By doing a simple running play every now and then, you force the defense to stay close and guard against the run.  Sometimes, the offense can catch the defense off guard by faking a run and freeing up their receivers.\\n\\nAlso, you don't have to gain massive yards on every single play.  Sometimes, it works best to gain a few yards at a time.  As long as you get the first down, you are in good shape.\",\n",
       "        'In most cases the O-Line is supposed to make a hole for the running back to go through. If you run too many plays to the outside/throws the defense will catch on.\\n\\nAlso, 2 5 yard plays gets you a new set of downs.',\n",
       "        \"I you don't like those type of plays, watch CFL.  We only get 3 downs so you can't afford to waste one.  Lots more passing.\"],\n",
       "       dtype=object),\n",
       " 'score': array([3, 2, 2, 2])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Keep the defense honest, get a feel for the pass rush, open up the passing game. An offense that's too one dimensional will fail. And those rushes up the middle can be busted wide open sometimes for big yardage.\",\n",
       "       \"If you throw the ball all the time, then the defense will adapt to always cover for a pass.  By doing a simple running play every now and then, you force the defense to stay close and guard against the run.  Sometimes, the offense can catch the defense off guard by faking a run and freeing up their receivers.\\n\\nAlso, you don't have to gain massive yards on every single play.  Sometimes, it works best to gain a few yards at a time.  As long as you get the first down, you are in good shape.\",\n",
       "       'In most cases the O-Line is supposed to make a hole for the running back to go through. If you run too many plays to the outside/throws the defense will catch on.\\n\\nAlso, 2 5 yard plays gets you a new set of downs.',\n",
       "       \"I you don't like those type of plays, watch CFL.  We only get 3 downs so you can't afford to waste one.  Lots more passing.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answers'][0].get ('text', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>new_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': 'Value 1', 'key2': 'Another Value'}</td>\n",
       "      <td>[Keep the defense honest, get a feel for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': 'Value 2', 'key2': 'More Value'}</td>\n",
       "      <td>[As someone who uses quality Premium, I wish t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        answers  \\\n",
       "0  {'text': 'Value 1', 'key2': 'Another Value'}   \n",
       "1     {'text': 'Value 2', 'key2': 'More Value'}   \n",
       "\n",
       "                                          new_column  \n",
       "0  [Keep the defense honest, get a feel for the p...  \n",
       "1  [As someone who uses quality Premium, I wish t...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'answers': [\n",
    "        {'text': 'Value 1', 'key2': 'Another Value'},\n",
    "        {'text': 'Value 2', 'key2': 'More Value'},\n",
    "        # Add more rows with dictionaries\n",
    "    ]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Extract 'text' values from 'answers' and create a new column 'new_column'\n",
    "df1['new_column'] = df['answers'].apply(lambda x: x.get('text', None))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>document</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>answers</th>\n",
       "      <th>title_urls</th>\n",
       "      <th>selftext_urls</th>\n",
       "      <th>answers_urls</th>\n",
       "      <th>text_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1oy5tc</td>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[Keep the defense honest, get a feel for the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2lojul</td>\n",
       "      <td>Why are different tiers (regular &lt; mid &lt; premi...</td>\n",
       "      <td>I've noticed that the difference in price betw...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['clwqgxl', 'clwqpjq', 'clwuh3s'], 't...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[As someone who uses quality Premium, I wish t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8v5e3s</td>\n",
       "      <td>Stars and Visibility</td>\n",
       "      <td>Why do stars in the night's sky seem to disapp...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['e1kpw6u'], 'text': ['It's a quirk o...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[It's a quirk of the human eye. At the center ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1v3wij</td>\n",
       "      <td>How do we know all the money the government is...</td>\n",
       "      <td>We hear about these large billion dollar bank ...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['ceohakd', 'ceoikhs', 'ceoji15', 'ce...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': ['http://dealbook.nytimes.com/2014/01/...</td>\n",
       "      <td>{'url': ['http://www.reuters.com/article/2013/...</td>\n",
       "      <td>[I'm pretty confident most of it isn't going b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2jlp6f</td>\n",
       "      <td>What are good and bad sides of manual and auto...</td>\n",
       "      <td>Please consider I'm not a driver. Automatic se...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['clcur3j'], 'text': ['Automatics wei...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[Automatics weigh more, so that alone makes ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558664</th>\n",
       "      <td>1cwijw</td>\n",
       "      <td>What was the biggest man-made loss of life in ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['c9kne6c'], 'text': ['The largest I ...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[The largest I can think of is the Firebombing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558665</th>\n",
       "      <td>8fucgx</td>\n",
       "      <td>Hi, I was hoping that someone would be able to...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['dy6lps1'], 'text': ['In Western Eur...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[In Western Europe there are very few specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558666</th>\n",
       "      <td>u4oom</td>\n",
       "      <td>What was the US Government's reaction to the D...</td>\n",
       "      <td>Obviously now there is an infrastructure in pl...</td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['c4sasnw'], 'text': ['The New Dealer...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[The New Dealers generally to a regional appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558667</th>\n",
       "      <td>bh9auu</td>\n",
       "      <td>What did America do after the dust bowl</td>\n",
       "      <td>Today I was learning about the dust bowl, whic...</td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['elrx4pm'], 'text': ['Agricultural p...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[Agricultural practices changed in part by nec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558668</th>\n",
       "      <td>af1ilk</td>\n",
       "      <td>Do animals have historical agency?</td>\n",
       "      <td>Can we define cod, cattle, or capybaras as act...</td>\n",
       "      <td></td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>{'a_id': ['eduwsnl'], 'text': ['Timothy Mitche...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>[Timothy Mitchell's book *Rule of Experts* has...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558669 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          q_id                                              title  \\\n",
       "0       1oy5tc  in football whats the point of wasting the fir...   \n",
       "1       2lojul  Why are different tiers (regular < mid < premi...   \n",
       "2       8v5e3s                               Stars and Visibility   \n",
       "3       1v3wij  How do we know all the money the government is...   \n",
       "4       2jlp6f  What are good and bad sides of manual and auto...   \n",
       "...        ...                                                ...   \n",
       "558664  1cwijw  What was the biggest man-made loss of life in ...   \n",
       "558665  8fucgx  Hi, I was hoping that someone would be able to...   \n",
       "558666   u4oom  What was the US Government's reaction to the D...   \n",
       "558667  bh9auu            What did America do after the dust bowl   \n",
       "558668  af1ilk                 Do animals have historical agency?   \n",
       "\n",
       "                                                 selftext document  \\\n",
       "0                                                                    \n",
       "1       I've noticed that the difference in price betw...            \n",
       "2       Why do stars in the night's sky seem to disapp...            \n",
       "3       We hear about these large billion dollar bank ...            \n",
       "4       Please consider I'm not a driver. Automatic se...            \n",
       "...                                                   ...      ...   \n",
       "558664                                                               \n",
       "558665                                                               \n",
       "558666  Obviously now there is an infrastructure in pl...            \n",
       "558667  Today I was learning about the dust bowl, whic...            \n",
       "558668  Can we define cod, cattle, or capybaras as act...            \n",
       "\n",
       "                subreddit                                            answers  \\\n",
       "0       explainlikeimfive  {'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...   \n",
       "1       explainlikeimfive  {'a_id': ['clwqgxl', 'clwqpjq', 'clwuh3s'], 't...   \n",
       "2       explainlikeimfive  {'a_id': ['e1kpw6u'], 'text': ['It's a quirk o...   \n",
       "3       explainlikeimfive  {'a_id': ['ceohakd', 'ceoikhs', 'ceoji15', 'ce...   \n",
       "4       explainlikeimfive  {'a_id': ['clcur3j'], 'text': ['Automatics wei...   \n",
       "...                   ...                                                ...   \n",
       "558664      AskHistorians  {'a_id': ['c9kne6c'], 'text': ['The largest I ...   \n",
       "558665      AskHistorians  {'a_id': ['dy6lps1'], 'text': ['In Western Eur...   \n",
       "558666      AskHistorians  {'a_id': ['c4sasnw'], 'text': ['The New Dealer...   \n",
       "558667      AskHistorians  {'a_id': ['elrx4pm'], 'text': ['Agricultural p...   \n",
       "558668      AskHistorians  {'a_id': ['eduwsnl'], 'text': ['Timothy Mitche...   \n",
       "\n",
       "         title_urls                                      selftext_urls  \\\n",
       "0       {'url': []}                                        {'url': []}   \n",
       "1       {'url': []}                                        {'url': []}   \n",
       "2       {'url': []}                                        {'url': []}   \n",
       "3       {'url': []}  {'url': ['http://dealbook.nytimes.com/2014/01/...   \n",
       "4       {'url': []}                                        {'url': []}   \n",
       "...             ...                                                ...   \n",
       "558664  {'url': []}                                        {'url': []}   \n",
       "558665  {'url': []}                                        {'url': []}   \n",
       "558666  {'url': []}                                        {'url': []}   \n",
       "558667  {'url': []}                                        {'url': []}   \n",
       "558668  {'url': []}                                        {'url': []}   \n",
       "\n",
       "                                             answers_urls  \\\n",
       "0                                             {'url': []}   \n",
       "1                                             {'url': []}   \n",
       "2                                             {'url': []}   \n",
       "3       {'url': ['http://www.reuters.com/article/2013/...   \n",
       "4                                             {'url': []}   \n",
       "...                                                   ...   \n",
       "558664                                        {'url': []}   \n",
       "558665                                        {'url': []}   \n",
       "558666                                        {'url': []}   \n",
       "558667                                        {'url': []}   \n",
       "558668                                        {'url': []}   \n",
       "\n",
       "                                                 text_ans  \n",
       "0       [Keep the defense honest, get a feel for the p...  \n",
       "1       [As someone who uses quality Premium, I wish t...  \n",
       "2       [It's a quirk of the human eye. At the center ...  \n",
       "3       [I'm pretty confident most of it isn't going b...  \n",
       "4       [Automatics weigh more, so that alone makes ga...  \n",
       "...                                                   ...  \n",
       "558664  [The largest I can think of is the Firebombing...  \n",
       "558665  [In Western Europe there are very few specific...  \n",
       "558666  [The New Dealers generally to a regional appro...  \n",
       "558667  [Agricultural practices changed in part by nec...  \n",
       "558668  [Timothy Mitchell's book *Rule of Experts* has...  \n",
       "\n",
       "[558669 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_ans'] = df['answers'].apply(lambda x: x.get('text', None))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Keep the defense honest, get a feel for the pass rush, open up the passing game. An offense that's too one dimensional will fail. And those rushes up the middle can be busted wide open sometimes for big yardage.\",\n",
       "       \"If you throw the ball all the time, then the defense will adapt to always cover for a pass.  By doing a simple running play every now and then, you force the defense to stay close and guard against the run.  Sometimes, the offense can catch the defense off guard by faking a run and freeing up their receivers.\\n\\nAlso, you don't have to gain massive yards on every single play.  Sometimes, it works best to gain a few yards at a time.  As long as you get the first down, you are in good shape.\",\n",
       "       'In most cases the O-Line is supposed to make a hole for the running back to go through. If you run too many plays to the outside/throws the defense will catch on.\\n\\nAlso, 2 5 yard plays gets you a new set of downs.',\n",
       "       \"I you don't like those type of plays, watch CFL.  We only get 3 downs so you can't afford to waste one.  Lots more passing.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_ans'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('text_ans', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Keep the defense honest, get a feel for the pa...\n",
       "1          If you throw the ball all the time, then the d...\n",
       "2          In most cases the O-Line is supposed to make a...\n",
       "3          I you don't like those type of plays, watch CF...\n",
       "4          As someone who uses quality Premium, I wish th...\n",
       "                                 ...                        \n",
       "1442899    The largest I can think of is the Firebombing ...\n",
       "1442900    In Western Europe there are very few specific ...\n",
       "1442901    The New Dealers generally to a regional approa...\n",
       "1442902    Agricultural practices changed in part by nece...\n",
       "1442903    Timothy Mitchell's book *Rule of Experts* has ...\n",
       "Name: text_ans, Length: 1442904, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_ans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>document</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>answers</th>\n",
       "      <th>title_urls</th>\n",
       "      <th>selftext_urls</th>\n",
       "      <th>answers_urls</th>\n",
       "      <th>text_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1oy5tc</td>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>Keep the defense honest, get a feel for the pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1oy5tc</td>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>If you throw the ball all the time, then the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1oy5tc</td>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>In most cases the O-Line is supposed to make a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1oy5tc</td>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>I you don't like those type of plays, watch CF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2lojul</td>\n",
       "      <td>Why are different tiers (regular &lt; mid &lt; premi...</td>\n",
       "      <td>I've noticed that the difference in price betw...</td>\n",
       "      <td></td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>{'a_id': ['clwqgxl', 'clwqpjq', 'clwuh3s'], 't...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>As someone who uses quality Premium, I wish th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     q_id                                              title  \\\n",
       "0  1oy5tc  in football whats the point of wasting the fir...   \n",
       "1  1oy5tc  in football whats the point of wasting the fir...   \n",
       "2  1oy5tc  in football whats the point of wasting the fir...   \n",
       "3  1oy5tc  in football whats the point of wasting the fir...   \n",
       "4  2lojul  Why are different tiers (regular < mid < premi...   \n",
       "\n",
       "                                            selftext document  \\\n",
       "0                                                               \n",
       "1                                                               \n",
       "2                                                               \n",
       "3                                                               \n",
       "4  I've noticed that the difference in price betw...            \n",
       "\n",
       "           subreddit                                            answers  \\\n",
       "0  explainlikeimfive  {'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...   \n",
       "1  explainlikeimfive  {'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...   \n",
       "2  explainlikeimfive  {'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...   \n",
       "3  explainlikeimfive  {'a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'cc...   \n",
       "4  explainlikeimfive  {'a_id': ['clwqgxl', 'clwqpjq', 'clwuh3s'], 't...   \n",
       "\n",
       "    title_urls selftext_urls answers_urls  \\\n",
       "0  {'url': []}   {'url': []}  {'url': []}   \n",
       "1  {'url': []}   {'url': []}  {'url': []}   \n",
       "2  {'url': []}   {'url': []}  {'url': []}   \n",
       "3  {'url': []}   {'url': []}  {'url': []}   \n",
       "4  {'url': []}   {'url': []}  {'url': []}   \n",
       "\n",
       "                                            text_ans  \n",
       "0  Keep the defense honest, get a feel for the pa...  \n",
       "1  If you throw the ball all the time, then the d...  \n",
       "2  In most cases the O-Line is supposed to make a...  \n",
       "3  I you don't like those type of plays, watch CF...  \n",
       "4  As someone who uses quality Premium, I wish th...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Keep the defense honest, get a feel for the pa...\n",
       "1          If you throw the ball all the time, then the d...\n",
       "2          In most cases the O-Line is supposed to make a...\n",
       "3          I you don't like those type of plays, watch CF...\n",
       "4          As someone who uses quality Premium, I wish th...\n",
       "                                 ...                        \n",
       "1442899    The largest I can think of is the Firebombing ...\n",
       "1442900    In Western Europe there are very few specific ...\n",
       "1442901    The New Dealers generally to a regional approa...\n",
       "1442902    Agricultural practices changed in part by nece...\n",
       "1442903    Timothy Mitchell's book *Rule of Experts* has ...\n",
       "Name: text_ans, Length: 1442904, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_ans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Keep the defense honest, get a feel for the pa...\n",
       "1    If you throw the ball all the time, then the d...\n",
       "2    In most cases the O-Line is supposed to make a...\n",
       "3    I you don't like those type of plays, watch CF...\n",
       "4    As someone who uses quality Premium, I wish th...\n",
       "Name: text_ans, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_ans'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seperated each answers isolated into new colmns. Lets convert it to datasets again and then tokenize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers',\n",
       "       'title_urls', 'selftext_urls', 'answers_urls', 'text_ans'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colomn names in df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>answers_urls</th>\n",
       "      <th>text_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>Keep the defense honest, get a feel for the pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>If you throw the ball all the time, then the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>In most cases the O-Line is supposed to make a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in football whats the point of wasting the fir...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>I you don't like those type of plays, watch CF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why are different tiers (regular &lt; mid &lt; premi...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>As someone who uses quality Premium, I wish th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442899</th>\n",
       "      <td>What was the biggest man-made loss of life in ...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>The largest I can think of is the Firebombing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442900</th>\n",
       "      <td>Hi, I was hoping that someone would be able to...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>In Western Europe there are very few specific ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442901</th>\n",
       "      <td>What was the US Government's reaction to the D...</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>The New Dealers generally to a regional approa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442902</th>\n",
       "      <td>What did America do after the dust bowl</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>Agricultural practices changed in part by nece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442903</th>\n",
       "      <td>Do animals have historical agency?</td>\n",
       "      <td>{'url': []}</td>\n",
       "      <td>Timothy Mitchell's book *Rule of Experts* has ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1442904 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title answers_urls  \\\n",
       "0        in football whats the point of wasting the fir...  {'url': []}   \n",
       "1        in football whats the point of wasting the fir...  {'url': []}   \n",
       "2        in football whats the point of wasting the fir...  {'url': []}   \n",
       "3        in football whats the point of wasting the fir...  {'url': []}   \n",
       "4        Why are different tiers (regular < mid < premi...  {'url': []}   \n",
       "...                                                    ...          ...   \n",
       "1442899  What was the biggest man-made loss of life in ...  {'url': []}   \n",
       "1442900  Hi, I was hoping that someone would be able to...  {'url': []}   \n",
       "1442901  What was the US Government's reaction to the D...  {'url': []}   \n",
       "1442902            What did America do after the dust bowl  {'url': []}   \n",
       "1442903                 Do animals have historical agency?  {'url': []}   \n",
       "\n",
       "                                                  text_ans  \n",
       "0        Keep the defense honest, get a feel for the pa...  \n",
       "1        If you throw the ball all the time, then the d...  \n",
       "2        In most cases the O-Line is supposed to make a...  \n",
       "3        I you don't like those type of plays, watch CF...  \n",
       "4        As someone who uses quality Premium, I wish th...  \n",
       "...                                                    ...  \n",
       "1442899  The largest I can think of is the Firebombing ...  \n",
       "1442900  In Western Europe there are very few specific ...  \n",
       "1442901  The New Dealers generally to a regional approa...  \n",
       "1442902  Agricultural practices changed in part by nece...  \n",
       "1442903  Timothy Mitchell's book *Rule of Experts* has ...  \n",
       "\n",
       "[1442904 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets drop un used colomns\n",
    "df_final = df.drop(['q_id', 'selftext', 'document', 'subreddit', 'answers','title_urls', 'selftext_urls',], axis=1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'answers_urls', 'text_ans'],\n",
       "    num_rows: 1442904\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets convert this df to datasets\n",
    "dataset_form_df = datasets.Dataset.from_pandas (df_final)\n",
    "dataset_form_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'text_ans'],\n",
       "    num_rows: 1442904\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_text = dataset_form_df.remove_columns(['answers_urls'])\n",
    "dataset_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_and_title (row):\n",
    "  return row['title'] + '\\n' + row['text_ans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1442904 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1442904/1442904 [01:23<00:00, 17292.02 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1442904\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_comb = dataset_text.map( lambda x: {'text' : combine_text_and_title ( x ) } , batched=False, remove_columns= dataset_text.column_names)\n",
    "ds_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"in football whats the point of wasting the first two plays with a rush - up the middle - not regular rush plays i get those\\nKeep the defense honest, get a feel for the pass rush, open up the passing game. An offense that's too one dimensional will fail. And those rushes up the middle can be busted wide open sometimes for big yardage.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_comb[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (3/3 shards): 100%|██████████| 1442904/1442904 [00:00<00:00, 1705621.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_comb.save_to_disk('eli5_dataset_title_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets load the dataset form drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c3db568557446484ac2691bcc00424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/1442904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train = datasets.DatasetDict({'train': dataset})\n",
    "ds_train.save_to_disk('eli5_dataset_title_text_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1442904\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = datasets.load_from_disk('eli5_dataset_title_text_train')\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub \n",
    "import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db64180a99944a468ae2a87be4ce7fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a23ef8be9e74979b2b75f2415b173e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/481 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa374ed82a304468949aa6335617475f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/481 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c327f7d10f4ae299070f35c988dd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/481 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "hugging_token = os.environ['HUGGINGFACE_TOKEN']\n",
    "\n",
    "ds_train.push_to_hub('Safeer143/eli5_dataset_title_text', token=hugging_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import datasets\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ckeckpoint = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckeckpoint)\n",
    "model = AutoModel.from_pretrained(ckeckpoint)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "dataset_to_token = datasets.load_from_disk('eli5_dataset_title_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1442904\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = tokenizer('What is the meaning of life?', return_tensors='pt').to('cuda') \n",
    "model_ans = model(**token, return_dict=True)\n",
    "model_ans.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is a mess. Its will break my computer\n",
    "# token1 = tokenizer ( dataset_to_token['text'] , return_tensors='pt', padding=True, truncation=True) \n",
    "# token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\"  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dbb9d59ff042028d0b7c68a523df3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1442904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1442904\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_1 = dataset_to_token.map(tokenize_function,  remove_columns=dataset_to_token.column_names)\n",
    "token_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_1 = token_1.add_column(name='text', column= dataset_to_token['text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101,\n",
       "   1999,\n",
       "   2374,\n",
       "   2054,\n",
       "   2015,\n",
       "   1996,\n",
       "   2391,\n",
       "   1997,\n",
       "   18313,\n",
       "   1996,\n",
       "   2034,\n",
       "   2048,\n",
       "   3248,\n",
       "   2007,\n",
       "   1037,\n",
       "   5481,\n",
       "   1011,\n",
       "   2039,\n",
       "   1996,\n",
       "   2690,\n",
       "   1011,\n",
       "   2025,\n",
       "   3180,\n",
       "   5481,\n",
       "   3248,\n",
       "   1045,\n",
       "   2131,\n",
       "   2216,\n",
       "   2562,\n",
       "   1996,\n",
       "   3639,\n",
       "   7481,\n",
       "   1010,\n",
       "   2131,\n",
       "   1037,\n",
       "   2514,\n",
       "   2005,\n",
       "   1996,\n",
       "   3413,\n",
       "   5481,\n",
       "   1010,\n",
       "   2330,\n",
       "   2039,\n",
       "   1996,\n",
       "   4458,\n",
       "   2208,\n",
       "   1012,\n",
       "   2019,\n",
       "   10048,\n",
       "   2008,\n",
       "   1005,\n",
       "   1055,\n",
       "   2205,\n",
       "   2028,\n",
       "   8789,\n",
       "   2097,\n",
       "   8246,\n",
       "   1012,\n",
       "   1998,\n",
       "   2216,\n",
       "   18545,\n",
       "   2039,\n",
       "   1996,\n",
       "   2690,\n",
       "   2064,\n",
       "   2022,\n",
       "   23142,\n",
       "   2898,\n",
       "   2330,\n",
       "   2823,\n",
       "   2005,\n",
       "   2502,\n",
       "   4220,\n",
       "   4270,\n",
       "   1012,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'text': \"in football whats the point of wasting the first two plays with a rush - up the middle - not regular rush plays i get those\\nKeep the defense honest, get a feel for the pass rush, open up the passing game. An offense that's too one dimensional will fail. And those rushes up the middle can be busted wide open sometimes for big yardage.\"}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (token_1[0]['input_ids'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d3443bd6354e3d98ee2829cffcb2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/12 shards):   0%|          | 0/1442904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# token_1.remove_columns(['text'])\n",
    "token_1.save_to_disk('eli5_dataset_title_text_tokenized_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'text'],\n",
       "    num_rows: 1442904\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets load the tokenized dataset and get the model second last hidden state\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import datasets\n",
    "import torch\n",
    "\n",
    "ckeckpoint = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckeckpoint)\n",
    "model = AutoModel.from_pretrained(ckeckpoint)\n",
    "\n",
    "load_dataset = datasets.load_from_disk('eli5_dataset_title_text_tokenized_pt')\n",
    "load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (load_dataset[0]['input_ids'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101,\n",
       "   1999,\n",
       "   2374,\n",
       "   2054,\n",
       "   2015,\n",
       "   1996,\n",
       "   2391,\n",
       "   1997,\n",
       "   18313,\n",
       "   1996,\n",
       "   2034,\n",
       "   2048,\n",
       "   3248,\n",
       "   2007,\n",
       "   1037,\n",
       "   5481,\n",
       "   1011,\n",
       "   2039,\n",
       "   1996,\n",
       "   2690,\n",
       "   1011,\n",
       "   2025,\n",
       "   3180,\n",
       "   5481,\n",
       "   3248,\n",
       "   1045,\n",
       "   2131,\n",
       "   2216,\n",
       "   2562,\n",
       "   1996,\n",
       "   3639,\n",
       "   7481,\n",
       "   1010,\n",
       "   2131,\n",
       "   1037,\n",
       "   2514,\n",
       "   2005,\n",
       "   1996,\n",
       "   3413,\n",
       "   5481,\n",
       "   1010,\n",
       "   2330,\n",
       "   2039,\n",
       "   1996,\n",
       "   4458,\n",
       "   2208,\n",
       "   1012,\n",
       "   2019,\n",
       "   10048,\n",
       "   2008,\n",
       "   1005,\n",
       "   1055,\n",
       "   2205,\n",
       "   2028,\n",
       "   8789,\n",
       "   2097,\n",
       "   8246,\n",
       "   1012,\n",
       "   1998,\n",
       "   2216,\n",
       "   18545,\n",
       "   2039,\n",
       "   1996,\n",
       "   2690,\n",
       "   2064,\n",
       "   2022,\n",
       "   23142,\n",
       "   2898,\n",
       "   2330,\n",
       "   2823,\n",
       "   2005,\n",
       "   2502,\n",
       "   4220,\n",
       "   4270,\n",
       "   1012,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'text': \"in football whats the point of wasting the first two plays with a rush - up the middle - not regular rush plays i get those\\nKeep the defense honest, get a feel for the pass rush, open up the passing game. An offense that's too one dimensional will fail. And those rushes up the middle can be busted wide open sometimes for big yardage.\"}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1999,  2374,  2054,  2015,  1996,  2391,  1997, 18313,  1996,\n",
       "          2034,  2048,  3248,  2007,  1037,  5481,  1011,  2039,  1996,  2690,\n",
       "          1011,  2025,  3180,  5481,  3248,  1045,  2131,  2216,  2562,  1996,\n",
       "          3639,  7481,  1010,  2131,  1037,  2514,  2005,  1996,  3413,  5481,\n",
       "          1010,  2330,  2039,  1996,  4458,  2208,  1012,  2019, 10048,  2008,\n",
       "          1005,  1055,  2205,  2028,  8789,  2097,  8246,  1012,  1998,  2216,\n",
       "         18545,  2039,  1996,  2690,  2064,  2022, 23142,  2898,  2330,  2823,\n",
       "          2005,  2502,  4220,  4270,  1012,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(load_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 57\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_ans \u001b[39m=\u001b[39m model(load_dataset[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\bert\\modeling_bert.py:969\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    968\u001b[0m \u001b[39melif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m    970\u001b[0m     input_shape \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39msize()\n\u001b[0;32m    971\u001b[0m \u001b[39melif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\modeling_utils.py:3821\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m   3818\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[39m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[1;32m-> 3821\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id \u001b[39min\u001b[39;00m input_ids[:, [\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m]]:\n\u001b[0;32m   3822\u001b[0m     warn_string \u001b[39m=\u001b[39m (\n\u001b[0;32m   3823\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3824\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3825\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3826\u001b[0m     )\n\u001b[0;32m   3828\u001b[0m     \u001b[39m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[0;32m   3829\u001b[0m     \u001b[39m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "model_ans = model(load_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ds = load_dataset.remove_columns(['text'])\n",
    "# model_ds.select(range(len(model_ds['input_ids']))).with_format('torch')\n",
    "# model_ds\n",
    "# model_ds = load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101,\n",
       "   1999,\n",
       "   2374,\n",
       "   2054,\n",
       "   2015,\n",
       "   1996,\n",
       "   2391,\n",
       "   1997,\n",
       "   18313,\n",
       "   1996,\n",
       "   2034,\n",
       "   2048,\n",
       "   3248,\n",
       "   2007,\n",
       "   1037,\n",
       "   5481,\n",
       "   1011,\n",
       "   2039,\n",
       "   1996,\n",
       "   2690,\n",
       "   1011,\n",
       "   2025,\n",
       "   3180,\n",
       "   5481,\n",
       "   3248,\n",
       "   1045,\n",
       "   2131,\n",
       "   2216,\n",
       "   2562,\n",
       "   1996,\n",
       "   3639,\n",
       "   7481,\n",
       "   1010,\n",
       "   2131,\n",
       "   1037,\n",
       "   2514,\n",
       "   2005,\n",
       "   1996,\n",
       "   3413,\n",
       "   5481,\n",
       "   1010,\n",
       "   2330,\n",
       "   2039,\n",
       "   1996,\n",
       "   4458,\n",
       "   2208,\n",
       "   1012,\n",
       "   2019,\n",
       "   10048,\n",
       "   2008,\n",
       "   1005,\n",
       "   1055,\n",
       "   2205,\n",
       "   2028,\n",
       "   8789,\n",
       "   2097,\n",
       "   8246,\n",
       "   1012,\n",
       "   1998,\n",
       "   2216,\n",
       "   18545,\n",
       "   2039,\n",
       "   1996,\n",
       "   2690,\n",
       "   2064,\n",
       "   2022,\n",
       "   23142,\n",
       "   2898,\n",
       "   2330,\n",
       "   2823,\n",
       "   2005,\n",
       "   2502,\n",
       "   4220,\n",
       "   4270,\n",
       "   1012,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets convert this dataset to tensor format\n",
    "dataset_small = model_ds.select(range(100) )\n",
    "dataset_small[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1999,  2374,  2054,  2015,  1996,  2391,  1997, 18313,  1996,\n",
       "          2034,  2048,  3248,  2007,  1037,  5481,  1011,  2039,  1996,  2690,\n",
       "          1011,  2025,  3180,  5481,  3248,  1045,  2131,  2216,  2065,  2017,\n",
       "          5466,  1996,  3608,  2035,  1996,  2051,  1010,  2059,  1996,  3639,\n",
       "          2097, 15581,  2000,  2467,  3104,  2005,  1037,  3413,  1012,  2011,\n",
       "          2725,  1037,  3722,  2770,  2377,  2296,  2085,  1998,  2059,  1010,\n",
       "          2017,  2486,  1996,  3639,  2000,  2994,  2485,  1998,  3457,  2114,\n",
       "          1996,  2448,  1012,  2823,  1010,  1996, 10048,  2064,  4608,  1996,\n",
       "          3639,  2125,  3457,  2011,  6904,  6834,  1037,  2448,  1998, 22198,\n",
       "          2039,  2037, 19278,  1012,  2036,  1010,  2017,  2123,  1005,  1056,\n",
       "          2031,  2000,  5114,  5294,  4210,  2006,  2296,  2309,  2377,  1012,\n",
       "          2823,  1010,  2009,  2573,  2190,  2000,  5114,  1037,  2261,  4210,\n",
       "          2012,  1037,  2051,  1012,  2004,  2146,  2004,  2017,  2131,  1996,\n",
       "          2034,  2091,  1010,  2017,  2024,  1999,  2204,  4338,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_tensor (row):\n",
    "  return torch.tensor(row)\n",
    "\n",
    "convert_to_tensor (dataset_small[1]['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1999,  2374,  2054,  2015,  1996,  2391,  1997, 18313,  1996,\n",
       "           2034,  2048,  3248,  2007,  1037,  5481,  1011,  2039,  1996,  2690,\n",
       "           1011,  2025,  3180,  5481,  3248,  1045,  2131,  2216,  2065,  2017,\n",
       "           5466,  1996,  3608,  2035,  1996,  2051,  1010,  2059,  1996,  3639,\n",
       "           2097, 15581,  2000,  2467,  3104,  2005,  1037,  3413,  1012,  2011,\n",
       "           2725,  1037,  3722,  2770,  2377,  2296,  2085,  1998,  2059,  1010,\n",
       "           2017,  2486,  1996,  3639,  2000,  2994,  2485,  1998,  3457,  2114,\n",
       "           1996,  2448,  1012,  2823,  1010,  1996, 10048,  2064,  4608,  1996,\n",
       "           3639,  2125,  3457,  2011,  6904,  6834,  1037,  2448,  1998, 22198,\n",
       "           2039,  2037, 19278,  1012,  2036,  1010,  2017,  2123,  1005,  1056,\n",
       "           2031,  2000,  5114,  5294,  4210,  2006,  2296,  2309,  2377,  1012,\n",
       "           2823,  1010,  2009,  2573,  2190,  2000,  5114,  1037,  2261,  4210,\n",
       "           2012,  1037,  2051,  1012,  2004,  2146,  2004,  2017,  2131,  1996,\n",
       "           2034,  2091,  1010,  2017,  2024,  1999,  2204,  4338,  1012,   102,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_ds_to_tensor (ds):\n",
    "    for keys in ds.keys():\n",
    "      ds[keys] = torch.tensor(ds[keys])\n",
    "    return ds\n",
    "  \n",
    "convert_ds_to_tensor (dataset_small[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f23708c6274970a3c5c2e17c050411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_in_tensor = dataset_small.map (lambda x :  convert_ds_to_tensor(x))\n",
    "ds_in_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101,\n",
       "   1999,\n",
       "   2374,\n",
       "   2054,\n",
       "   2015,\n",
       "   1996,\n",
       "   2391,\n",
       "   1997,\n",
       "   18313,\n",
       "   1996,\n",
       "   2034,\n",
       "   2048,\n",
       "   3248,\n",
       "   2007,\n",
       "   1037,\n",
       "   5481,\n",
       "   1011,\n",
       "   2039,\n",
       "   1996,\n",
       "   2690,\n",
       "   1011,\n",
       "   2025,\n",
       "   3180,\n",
       "   5481,\n",
       "   3248,\n",
       "   1045,\n",
       "   2131,\n",
       "   2216,\n",
       "   2562,\n",
       "   1996,\n",
       "   3639,\n",
       "   7481,\n",
       "   1010,\n",
       "   2131,\n",
       "   1037,\n",
       "   2514,\n",
       "   2005,\n",
       "   1996,\n",
       "   3413,\n",
       "   5481,\n",
       "   1010,\n",
       "   2330,\n",
       "   2039,\n",
       "   1996,\n",
       "   4458,\n",
       "   2208,\n",
       "   1012,\n",
       "   2019,\n",
       "   10048,\n",
       "   2008,\n",
       "   1005,\n",
       "   1055,\n",
       "   2205,\n",
       "   2028,\n",
       "   8789,\n",
       "   2097,\n",
       "   8246,\n",
       "   1012,\n",
       "   1998,\n",
       "   2216,\n",
       "   18545,\n",
       "   2039,\n",
       "   1996,\n",
       "   2690,\n",
       "   2064,\n",
       "   2022,\n",
       "   23142,\n",
       "   2898,\n",
       "   2330,\n",
       "   2823,\n",
       "   2005,\n",
       "   2502,\n",
       "   4220,\n",
       "   4270,\n",
       "   1012,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_in_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 64\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_last_hidden_state\u001b[39m (row):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y112sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrow)[\u001b[39m\"\u001b[39m\u001b[39mlast_hidden_state\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y112sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model_out \u001b[39m=\u001b[39m model_last_hidden_state(ds_in_tensor[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y112sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_out\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 64\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_last_hidden_state\u001b[39m (row):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y112sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrow)[\u001b[39m\"\u001b[39m\u001b[39mlast_hidden_state\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\bert\\modeling_bert.py:970\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39melif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[1;32m--> 970\u001b[0m     input_shape \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39;49msize()\n\u001b[0;32m    971\u001b[0m \u001b[39melif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    972\u001b[0m     input_shape \u001b[39m=\u001b[39m inputs_embeds\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "def model_last_hidden_state (row):\n",
    "  return model(**row)[\"last_hidden_state\"][:,0].detach().cpu().numpy()[0]\n",
    "\n",
    "model_out = model_last_hidden_state(ds_in_tensor[0])\n",
    "model_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_small.column_names\n",
    "dataset_small.select_columns(['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 66\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# dataset_small.map(tokenize_from_model)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m tokenize_from_model (dataset_small)\n",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 66\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m (ds_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# tensor = dataset_small.map(convert_ds_to_tensor)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m tensor \u001b[39m=\u001b[39m convert_ds_to_tensor(dataset_small)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m (tensor)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# token = model_last_hidden_state(tensor)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 66\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_ds_to_tensor\u001b[39m (ds):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m keys \u001b[39min\u001b[39;00m ds\u001b[39m.\u001b[39;49mkeys():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m       ds[keys] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(ds[keys])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y131sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ds\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# If I am performing these indevidual steps they are working fine. But when I am trying to combine them in a function it is not working\n",
    "# the resaon I see is that when One function to convert ds to tensor is applied its not returning the tensor format when map is applied\n",
    "\n",
    "def tokenize_from_model (ds):\n",
    "    ds_val = ds\n",
    "    print (ds_val.column_names)\n",
    "    if len (ds_val.column_names) > 3:\n",
    "      ds_val = ds.select_columns(['input_ids', 'token_type_ids', 'attention_mask'])\n",
    "    print (ds_val)\n",
    "    # tensor = dataset_small.map(convert_ds_to_tensor)\n",
    "    tensor = convert_ds_to_tensor(dataset_small)\n",
    "    print (tensor)\n",
    "    # token = model_last_hidden_state(tensor)\n",
    "    return tensor\n",
    "    \n",
    "# dataset_small.map(tokenize_from_model)\n",
    "tokenize_from_model (dataset_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b89471c33b49a38780856ba5a0f880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Provided `function` which is applied to all elements of table returns a variable of type <class 'numpy.ndarray'>. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 67\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     token \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mds)[\u001b[39m\"\u001b[39m\u001b[39mlast_hidden_state\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y113sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m token\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y113sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dataset_small\u001b[39m.\u001b[39;49mmap(token)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    591\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 592\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    593\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    554\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    555\u001b[0m }\n\u001b[0;32m    556\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    558\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    559\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:3097\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3090\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3091\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   3092\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3093\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3094\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[0;32m   3095\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3096\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3097\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3098\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   3099\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:3450\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3448\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   3449\u001b[0m \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3450\u001b[0m     example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[0;32m   3451\u001b[0m     \u001b[39mif\u001b[39;00m update_data:\n\u001b[0;32m   3452\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:3364\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3361\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3362\u001b[0m     \u001b[39m# Check if the function returns updated examples\u001b[39;00m\n\u001b[0;32m   3363\u001b[0m     update_data \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable, pd\u001b[39m.\u001b[39mDataFrame))\n\u001b[1;32m-> 3364\u001b[0m     validate_function_output(processed_inputs, indices)\n\u001b[0;32m   3365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m update_data:\n\u001b[0;32m   3366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# Nothing to update, let's move on\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:3309\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.validate_function_output\u001b[1;34m(processed_inputs, indices)\u001b[0m\n\u001b[0;32m   3307\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Validate output of the map function.\"\"\"\u001b[39;00m\n\u001b[0;32m   3308\u001b[0m \u001b[39mif\u001b[39;00m processed_inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable, pd\u001b[39m.\u001b[39mDataFrame)):\n\u001b[1;32m-> 3309\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   3310\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProvided `function` which is applied to all elements of table returns a variable of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(processed_inputs)\u001b[39m}\u001b[39;00m\u001b[39m. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3311\u001b[0m     )\n\u001b[0;32m   3312\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(indices, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, Mapping):\n\u001b[0;32m   3313\u001b[0m     allowed_batch_return_types \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m, np\u001b[39m.\u001b[39mndarray, pd\u001b[39m.\u001b[39mSeries)\n",
      "\u001b[1;31mTypeError\u001b[0m: Provided `function` which is applied to all elements of table returns a variable of type <class 'numpy.ndarray'>. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects."
     ]
    }
   ],
   "source": [
    "def token (ds):\n",
    "    tenser = convert_ds_to_tensor(ds)\n",
    "    token = model(**ds)[\"last_hidden_state\"][:,0].detach().cpu().numpy()[0]\n",
    "    return token\n",
    "\n",
    "dataset_small.map(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 62\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m model_ds, return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_ds' is not defined"
     ]
    }
   ],
   "source": [
    "model(** model_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1442904\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "# datasets.load_dataset (\"Safeer143/marian-finetuned-kde4-en-to-fr-4-epochs-10000-samples\")\n",
    "dataset = datasets.load_from_disk (\"eli5_dataset_title_text\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa60a56db884393b1e6ab0d6ae38b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6fab373b644c98af2ba5c0677d4d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5658f178ce346fb8af6bf8fcfa3e8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/462 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub('eli5_dataset_title_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc883c55eb74242954d82d1f6745bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7212f21d5d240d79256d4b52a6f7c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b0115cc99f47ed96940d49d442b645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/190M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 72\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y145sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset_online \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mload_dataset(\u001b[39m'\u001b[39;49m\u001b[39mSafeer143/eli5_dataset_title_text\u001b[39;49m\u001b[39m'\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\load.py:2153\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   2150\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[0;32m   2152\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 2153\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[0;32m   2154\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   2155\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   2156\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[0;32m   2157\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[0;32m   2158\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m   2159\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   2160\u001b[0m )\n\u001b[0;32m   2162\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   2163\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[0;32m   2164\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[0;32m   2165\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\builder.py:954\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    952\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[1;32m--> 954\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m    955\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[0;32m    956\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[0;32m    957\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[0;32m    958\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[0;32m    959\u001b[0m     )\n\u001b[0;32m    960\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\builder.py:1027\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m   1025\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name)\n\u001b[0;32m   1026\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[1;32m-> 1027\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[0;32m   1029\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\packaged_modules\\parquet\\parquet.py:34\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files:\n\u001b[0;32m     33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m data_files \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdata_files)\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_files, (\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m     36\u001b[0m     files \u001b[39m=\u001b[39m data_files\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\download\\download_manager.py:565\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_and_extract\u001b[39m(\u001b[39mself\u001b[39m, url_or_urls):\n\u001b[0;32m    550\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \n\u001b[0;32m    552\u001b[0m \u001b[39m    Is roughly equivalent to:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[39m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload(url_or_urls))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\download\\download_manager.py:428\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    425\u001b[0m download_func \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[0;32m    427\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m--> 428\u001b[0m downloaded_path_or_paths \u001b[39m=\u001b[39m map_nested(\n\u001b[0;32m    429\u001b[0m     download_func,\n\u001b[0;32m    430\u001b[0m     url_or_urls,\n\u001b[0;32m    431\u001b[0m     map_tuple\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    432\u001b[0m     num_proc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mnum_proc,\n\u001b[0;32m    433\u001b[0m     disable_tqdm\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_progress_bar_enabled(),\n\u001b[0;32m    434\u001b[0m     desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading data files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    435\u001b[0m )\n\u001b[0;32m    436\u001b[0m duration \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m    437\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading took \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m.\u001b[39mtotal_seconds()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\utils\\py_utils.py:464\u001b[0m, in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[0;32m    462\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[1;32m--> 464\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m    465\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    466\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[0;32m    467\u001b[0m     ]\n\u001b[0;32m    468\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\utils\\py_utils.py:465\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    462\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[0;32m    464\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 465\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[0;32m    466\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[0;32m    467\u001b[0m     ]\n\u001b[0;32m    468\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\utils\\py_utils.py:384\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: _single_map_nested((function, v, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pbar}\n\u001b[0;32m    383\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m     mapped \u001b[39m=\u001b[39m [_single_map_nested((function, v, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pbar]\n\u001b[0;32m    385\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    386\u001b[0m         \u001b[39mreturn\u001b[39;00m mapped\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\utils\\py_utils.py:384\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: _single_map_nested((function, v, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pbar}\n\u001b[0;32m    383\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m     mapped \u001b[39m=\u001b[39m [_single_map_nested((function, v, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pbar]\n\u001b[0;32m    385\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    386\u001b[0m         \u001b[39mreturn\u001b[39;00m mapped\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\utils\\py_utils.py:367\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39m# Singleton first to spare some computation\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[0;32m    369\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\download\\download_manager.py:454\u001b[0m, in \u001b[0;36mDownloadManager._download\u001b[1;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[0;32m    452\u001b[0m     \u001b[39m# append the relative path to the base_path\u001b[39;00m\n\u001b[0;32m    453\u001b[0m     url_or_filename \u001b[39m=\u001b[39m url_or_path_join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path, url_or_filename)\n\u001b[1;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m cached_path(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\utils\\file_utils.py:182\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     url_or_filename \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(url_or_filename)\n\u001b[0;32m    180\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    181\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    183\u001b[0m         url_or_filename,\n\u001b[0;32m    184\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    185\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[0;32m    186\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    187\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[0;32m    188\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[0;32m    189\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[0;32m    190\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[0;32m    191\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    192\u001b[0m         token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mtoken,\n\u001b[0;32m    193\u001b[0m         ignore_url_params\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mignore_url_params,\n\u001b[0;32m    194\u001b[0m         storage_options\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    195\u001b[0m         download_desc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdownload_desc,\n\u001b[0;32m    196\u001b[0m     )\n\u001b[0;32m    197\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    198\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\utils\\file_utils.py:642\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc)\u001b[0m\n\u001b[0;32m    640\u001b[0m     ftp_get(url, temp_file)\n\u001b[0;32m    641\u001b[0m \u001b[39melif\u001b[39;00m scheme \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 642\u001b[0m     fsspec_get(url, temp_file, storage_options\u001b[39m=\u001b[39;49mstorage_options, desc\u001b[39m=\u001b[39;49mdownload_desc)\n\u001b[0;32m    643\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    644\u001b[0m     http_get(\n\u001b[0;32m    645\u001b[0m         url,\n\u001b[0;32m    646\u001b[0m         temp_file,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    652\u001b[0m         desc\u001b[39m=\u001b[39mdownload_desc,\n\u001b[0;32m    653\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\utils\\file_utils.py:367\u001b[0m, in \u001b[0;36mfsspec_get\u001b[1;34m(url, temp_file, storage_options, desc)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGET can be called with at most one path but was called with \u001b[39m\u001b[39m{\u001b[39;00mpaths\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    359\u001b[0m callback \u001b[39m=\u001b[39m TqdmCallback(\n\u001b[0;32m    360\u001b[0m     tqdm_kwargs\u001b[39m=\u001b[39m{\n\u001b[0;32m    361\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdesc\u001b[39m\u001b[39m\"\u001b[39m: desc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mDownloading\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     }\n\u001b[0;32m    366\u001b[0m )\n\u001b[1;32m--> 367\u001b[0m fs\u001b[39m.\u001b[39;49mget_file(paths[\u001b[39m0\u001b[39;49m], temp_file\u001b[39m.\u001b[39;49mname, callback\u001b[39m=\u001b[39;49mcallback)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fsspec\\spec.py:882\u001b[0m, in \u001b[0;36mAbstractFileSystem.get_file\u001b[1;34m(self, rpath, lpath, callback, outfile, **kwargs)\u001b[0m\n\u001b[0;32m    880\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[39mwhile\u001b[39;00m data:\n\u001b[1;32m--> 882\u001b[0m     data \u001b[39m=\u001b[39m f1\u001b[39m.\u001b[39;49mread(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocksize)\n\u001b[0;32m    883\u001b[0m     segment_len \u001b[39m=\u001b[39m outfile\u001b[39m.\u001b[39mwrite(data)\n\u001b[0;32m    884\u001b[0m     \u001b[39mif\u001b[39;00m segment_len \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fsspec\\spec.py:1790\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[1;34m(self, length)\u001b[0m\n\u001b[0;32m   1787\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1788\u001b[0m     \u001b[39m# don't even bother calling fetch\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1790\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache\u001b[39m.\u001b[39;49m_fetch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc \u001b[39m+\u001b[39;49m length)\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(out)\n\u001b[0;32m   1792\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fsspec\\caching.py:156\u001b[0m, in \u001b[0;36mReadAheadCache._fetch\u001b[1;34m(self, start, end)\u001b[0m\n\u001b[0;32m    154\u001b[0m     part \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m end \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, end \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize)\n\u001b[1;32m--> 156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetcher(start, end)  \u001b[39m# new block replaces old\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m=\u001b[39m start\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\huggingface_hub\\hf_file_system.py:422\u001b[0m, in \u001b[0;36mHfFileSystemFile._fetch_range\u001b[1;34m(self, start, end)\u001b[0m\n\u001b[0;32m    415\u001b[0m headers \u001b[39m=\u001b[39m {\n\u001b[0;32m    416\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrange\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbytes=\u001b[39m\u001b[39m{\u001b[39;00mstart\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    417\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39m_api\u001b[39m.\u001b[39m_build_hf_headers(),\n\u001b[0;32m    418\u001b[0m }\n\u001b[0;32m    419\u001b[0m url \u001b[39m=\u001b[39m (\n\u001b[0;32m    420\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mREPO_TYPES_URL_PREFIXES\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mrepo_type,\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m/resolve/\u001b[39m\u001b[39m{\u001b[39;00msafe_quote(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mrevision)\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00msafe_quote(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved_path\u001b[39m.\u001b[39mpath_in_repo)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    421\u001b[0m )\n\u001b[1;32m--> 422\u001b[0m r \u001b[39m=\u001b[39m http_backoff(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    423\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m    424\u001b[0m \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\huggingface_hub\\utils\\_http.py:258\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[0;32m    257\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m retry_on_status_codes:\n\u001b[0;32m    260\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:725\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    723\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 725\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:725\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    723\u001b[0m     \u001b[39m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_redirects(r, request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 725\u001b[0m     history \u001b[39m=\u001b[39m [resp \u001b[39mfor\u001b[39;00m resp \u001b[39min\u001b[39;00m gen]\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     history \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:266\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[39myield\u001b[39;00m req\n\u001b[0;32m    264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\n\u001b[0;32m    267\u001b[0m         req,\n\u001b[0;32m    268\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    269\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    270\u001b[0m         verify\u001b[39m=\u001b[39;49mverify,\n\u001b[0;32m    271\u001b[0m         cert\u001b[39m=\u001b[39;49mcert,\n\u001b[0;32m    272\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    273\u001b[0m         allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    274\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49madapter_kwargs,\n\u001b[0;32m    275\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     extract_cookies_to_jar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcookies, prepared_request, resp\u001b[39m.\u001b[39mraw)\n\u001b[0;32m    279\u001b[0m     \u001b[39m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\huggingface_hub\\utils\\_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     65\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\http\\client.py:1344\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1343\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1344\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1345\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1346\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\http\\client.py:307\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    309\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\http\\client.py:268\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 268\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    270\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_online = datasets.load_dataset('Safeer143/eli5_dataset_title_text', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1442904\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import datasets\n",
    "import torch\n",
    "\n",
    "ckeckpoint = 'bert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckeckpoint)\n",
    "model = AutoModel.from_pretrained(ckeckpoint)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "dataset = datasets.load_from_disk('eli5_dataset_title_text')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_20000 = dataset.shuffle(52).select(range(20000) )\n",
    "dataset_20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets tokenize this dataset and get the model last hidden state for fiass embeddings\n",
    "def model_last_hidden_state (row):\n",
    "  token = tokenizer(row['text'], return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "\n",
    "  return model(**token)[\"last_hidden_state\"][:,0].detach().cpu().numpy()[0]\n",
    "# model_last_hidden_state (dataset_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0b8336a38a492a9c35afaf96309fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'embeddings'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ds_20k = dataset_20000.map(lambda x : {'embeddings' : model_last_hidden_state(x) } )\n",
    "token_ds_20k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2790078818798065,\n",
       " -0.45313718914985657,\n",
       " 0.10761097073554993,\n",
       " 0.14402496814727783,\n",
       " -1.12210214138031,\n",
       " 0.08929474651813507,\n",
       " 0.9192380309104919,\n",
       " 1.004791021347046,\n",
       " 0.10120101273059845,\n",
       " -0.10320691764354706,\n",
       " 0.5131825804710388,\n",
       " -0.5070419907569885,\n",
       " -0.9077893495559692,\n",
       " 0.9148262739181519,\n",
       " 0.5832650065422058,\n",
       " -0.08860179036855698,\n",
       " -0.41548851132392883,\n",
       " 0.2624037265777588,\n",
       " 0.14002707600593567,\n",
       " 0.14255189895629883,\n",
       " 0.5409890413284302,\n",
       " 0.11273255199193954,\n",
       " -0.04303742200136185,\n",
       " 0.4311380684375763,\n",
       " 0.08510442823171616,\n",
       " -0.12325286865234375,\n",
       " 0.25632357597351074,\n",
       " -0.03572508692741394,\n",
       " 0.2654544711112976,\n",
       " -0.23880396783351898,\n",
       " -0.41565513610839844,\n",
       " -0.010069145821034908,\n",
       " -0.3433397114276886,\n",
       " -0.6735960245132446,\n",
       " 0.5280308127403259,\n",
       " -0.25775858759880066,\n",
       " 0.16038917005062103,\n",
       " 0.2434626966714859,\n",
       " -0.1035999208688736,\n",
       " 0.5986385345458984,\n",
       " -0.9207701086997986,\n",
       " -0.24668370187282562,\n",
       " 0.04567432776093483,\n",
       " -0.03752829134464264,\n",
       " -0.15332655608654022,\n",
       " -0.7106544971466064,\n",
       " -3.2359204292297363,\n",
       " -0.09229395538568497,\n",
       " -0.2700362503528595,\n",
       " -0.05308040603995323,\n",
       " -0.32467153668403625,\n",
       " -0.4421361982822418,\n",
       " 0.5698075294494629,\n",
       " 0.6136069893836975,\n",
       " 0.1279871016740799,\n",
       " 0.532917320728302,\n",
       " -0.15050794184207916,\n",
       " -0.24814200401306152,\n",
       " -0.4772883653640747,\n",
       " 0.038364458829164505,\n",
       " -0.2677615284919739,\n",
       " 0.2524135410785675,\n",
       " -0.39415186643600464,\n",
       " -0.3329295516014099,\n",
       " -0.398639440536499,\n",
       " 0.1303476244211197,\n",
       " -0.013838076032698154,\n",
       " 0.7591789364814758,\n",
       " -0.789478600025177,\n",
       " -0.4429526925086975,\n",
       " -0.5441162586212158,\n",
       " 0.0723317340016365,\n",
       " 0.19896380603313446,\n",
       " 0.04717355966567993,\n",
       " -0.732849657535553,\n",
       " -0.1854265183210373,\n",
       " -0.4822944700717926,\n",
       " 0.42265641689300537,\n",
       " -0.2728005647659302,\n",
       " -1.0232696533203125,\n",
       " -0.5588884353637695,\n",
       " 0.5084356069564819,\n",
       " -0.04131496697664261,\n",
       " 0.11813228577375412,\n",
       " 0.712127685546875,\n",
       " 0.6081625819206238,\n",
       " 0.4207233786582947,\n",
       " -0.200011745095253,\n",
       " 0.18891572952270508,\n",
       " 0.4006741940975189,\n",
       " -0.5044365525245667,\n",
       " -0.16329893469810486,\n",
       " -0.1630489081144333,\n",
       " 1.1087771654129028,\n",
       " 0.3397136926651001,\n",
       " -0.46956056356430054,\n",
       " 0.3614940643310547,\n",
       " 0.39830511808395386,\n",
       " -0.23394951224327087,\n",
       " 0.8093372583389282,\n",
       " 1.130994439125061,\n",
       " -0.43090856075286865,\n",
       " -0.11008342355489731,\n",
       " -0.856791079044342,\n",
       " 0.8670299053192139,\n",
       " -0.33335357904434204,\n",
       " 0.03287656232714653,\n",
       " -0.15384139120578766,\n",
       " 0.8596286177635193,\n",
       " -2.0295615196228027,\n",
       " 0.5498130917549133,\n",
       " -0.201755553483963,\n",
       " -0.01597231812775135,\n",
       " -0.6921010613441467,\n",
       " 0.04064016416668892,\n",
       " -0.15254901349544525,\n",
       " 0.4715566039085388,\n",
       " -0.8698592782020569,\n",
       " -0.22332803905010223,\n",
       " -0.10545323044061661,\n",
       " 0.45058465003967285,\n",
       " -0.09406169503927231,\n",
       " -0.17494525015354156,\n",
       " 0.21613313257694244,\n",
       " -0.11633401364088058,\n",
       " -0.24794670939445496,\n",
       " -0.9808428883552551,\n",
       " 0.020793458446860313,\n",
       " 0.21510274708271027,\n",
       " 0.22912532091140747,\n",
       " 0.2704527974128723,\n",
       " 0.7039464116096497,\n",
       " -0.2858777940273285,\n",
       " -1.494559407234192,\n",
       " -0.1978377103805542,\n",
       " 0.13269205391407013,\n",
       " 0.7543052434921265,\n",
       " 0.44578373432159424,\n",
       " -0.11730358004570007,\n",
       " -0.28988882899284363,\n",
       " -0.9289349913597107,\n",
       " -0.503568708896637,\n",
       " -1.6904126405715942,\n",
       " -0.14820747077465057,\n",
       " 0.737259566783905,\n",
       " -0.09756128489971161,\n",
       " -0.9921219944953918,\n",
       " -0.18058596551418304,\n",
       " 0.3991871774196625,\n",
       " -0.42210862040519714,\n",
       " -0.1686302125453949,\n",
       " 0.008722622878849506,\n",
       " -0.37567654252052307,\n",
       " -0.16223885118961334,\n",
       " -0.1036393940448761,\n",
       " -0.4064424932003021,\n",
       " -0.7500118613243103,\n",
       " 0.09201905876398087,\n",
       " 0.20810635387897491,\n",
       " 0.694133460521698,\n",
       " 0.836568295955658,\n",
       " -0.6789782047271729,\n",
       " 0.22237102687358856,\n",
       " -0.14117205142974854,\n",
       " -0.37483543157577515,\n",
       " 0.40916576981544495,\n",
       " 1.0190006494522095,\n",
       " 0.8069266676902771,\n",
       " -0.009059217758476734,\n",
       " 0.04425515606999397,\n",
       " -0.05103288218379021,\n",
       " 0.46060582995414734,\n",
       " 0.9230462312698364,\n",
       " 0.10294000059366226,\n",
       " 0.9841561913490295,\n",
       " -0.23509421944618225,\n",
       " -0.12523166835308075,\n",
       " 0.8649607300758362,\n",
       " 0.19235734641551971,\n",
       " -0.05513870716094971,\n",
       " -0.8621857762336731,\n",
       " -0.30035555362701416,\n",
       " 0.5574662089347839,\n",
       " 0.7175052762031555,\n",
       " 0.7095022201538086,\n",
       " 0.2705022692680359,\n",
       " 0.12783388793468475,\n",
       " -0.3177435100078583,\n",
       " -0.8604699969291687,\n",
       " 0.2408914566040039,\n",
       " 0.04373429715633392,\n",
       " -0.6569364070892334,\n",
       " 0.21107959747314453,\n",
       " 0.6167510151863098,\n",
       " 0.9661750793457031,\n",
       " -0.7875277400016785,\n",
       " 0.2887992858886719,\n",
       " -0.8019115328788757,\n",
       " 0.3326496183872223,\n",
       " 0.10032720118761063,\n",
       " -0.2880820035934448,\n",
       " 0.4094615578651428,\n",
       " 0.04537895321846008,\n",
       " 0.3071616291999817,\n",
       " -0.09744486212730408,\n",
       " 3.216437339782715,\n",
       " -0.12665128707885742,\n",
       " 0.526424765586853,\n",
       " -0.5778039693832397,\n",
       " 0.27219778299331665,\n",
       " -1.1396485567092896,\n",
       " 0.024565333500504494,\n",
       " -0.5985351204872131,\n",
       " -0.14187921583652496,\n",
       " -0.4046279788017273,\n",
       " -0.10839379578828812,\n",
       " 0.4875682294368744,\n",
       " 0.25906798243522644,\n",
       " -0.08348076790571213,\n",
       " -0.18659421801567078,\n",
       " 0.29966413974761963,\n",
       " -0.15910060703754425,\n",
       " -0.35583221912384033,\n",
       " -0.3665544092655182,\n",
       " 0.2030545026063919,\n",
       " 0.7849222421646118,\n",
       " -0.008512908592820168,\n",
       " 0.46268582344055176,\n",
       " -0.10720869153738022,\n",
       " -1.8414701223373413,\n",
       " -0.03245653957128525,\n",
       " 0.2473384290933609,\n",
       " -0.4154953062534332,\n",
       " 0.18844591081142426,\n",
       " -0.43207424879074097,\n",
       " 0.11774270236492157,\n",
       " -0.16761615872383118,\n",
       " -0.5099419355392456,\n",
       " 0.28579309582710266,\n",
       " -0.7025275230407715,\n",
       " 0.28287139534950256,\n",
       " 0.4251661002635956,\n",
       " 0.8158259391784668,\n",
       " 0.4076577126979828,\n",
       " 0.1587546020746231,\n",
       " 0.09133390337228775,\n",
       " 0.19426101446151733,\n",
       " -0.5039622783660889,\n",
       " 0.8410376310348511,\n",
       " 0.2729247510433197,\n",
       " 0.09572204947471619,\n",
       " -0.1489609032869339,\n",
       " -0.10133851319551468,\n",
       " -0.8410347104072571,\n",
       " -0.5937675833702087,\n",
       " -0.10651878267526627,\n",
       " 0.4586869478225708,\n",
       " 0.38533055782318115,\n",
       " -0.529917299747467,\n",
       " 0.24233992397785187,\n",
       " -0.11783366650342941,\n",
       " 0.11870758980512619,\n",
       " 0.6049972772598267,\n",
       " 0.5526522994041443,\n",
       " -0.5471848845481873,\n",
       " -0.5771237015724182,\n",
       " -0.30205196142196655,\n",
       " -0.3936726450920105,\n",
       " -0.4900028109550476,\n",
       " -0.3657514154911041,\n",
       " 0.027906233444809914,\n",
       " -0.581109881401062,\n",
       " 0.005889644846320152,\n",
       " -1.564095377922058,\n",
       " 0.552282452583313,\n",
       " 0.06468494236469269,\n",
       " 0.42434272170066833,\n",
       " 0.5584249496459961,\n",
       " -0.8556753396987915,\n",
       " 0.0859110876917839,\n",
       " 0.34770700335502625,\n",
       " 0.5587683320045471,\n",
       " -0.590954065322876,\n",
       " 0.2546560764312744,\n",
       " -0.01325531117618084,\n",
       " 0.5528458952903748,\n",
       " 0.11031992733478546,\n",
       " -0.4480724632740021,\n",
       " 0.5603660941123962,\n",
       " -0.13263526558876038,\n",
       " 0.05357377603650093,\n",
       " -0.0022237449884414673,\n",
       " 0.040886420756578445,\n",
       " 0.17524638772010803,\n",
       " -0.1919236034154892,\n",
       " -0.7419896721839905,\n",
       " 0.07655224949121475,\n",
       " 0.1216806024312973,\n",
       " 0.14272814989089966,\n",
       " -0.504152238368988,\n",
       " -0.26219442486763,\n",
       " 0.0294088963419199,\n",
       " -0.42463722825050354,\n",
       " 0.4903067350387573,\n",
       " 0.025321856141090393,\n",
       " 0.12255187332630157,\n",
       " 0.37553274631500244,\n",
       " -0.3891265392303467,\n",
       " -2.378765344619751,\n",
       " 0.13981997966766357,\n",
       " -0.23288550972938538,\n",
       " -0.41378626227378845,\n",
       " 0.1670343279838562,\n",
       " 0.3283594846725464,\n",
       " 0.2563164234161377,\n",
       " -0.12920257449150085,\n",
       " -1.0793818235397339,\n",
       " -0.6962274312973022,\n",
       " 0.2572273015975952,\n",
       " -0.17436787486076355,\n",
       " 0.3639536201953888,\n",
       " -0.1339646726846695,\n",
       " 0.06240415573120117,\n",
       " 0.467675119638443,\n",
       " 0.682517945766449,\n",
       " -0.2810472846031189,\n",
       " 0.8068125247955322,\n",
       " 0.5439980030059814,\n",
       " -0.1869044452905655,\n",
       " -0.05827949568629265,\n",
       " 0.5555307865142822,\n",
       " -0.3763435184955597,\n",
       " 0.7357180714607239,\n",
       " 0.24013222754001617,\n",
       " -0.5586979985237122,\n",
       " -0.48050591349601746,\n",
       " -0.3019068241119385,\n",
       " 0.49230116605758667,\n",
       " -0.5511921644210815,\n",
       " -0.570147693157196,\n",
       " 0.25246572494506836,\n",
       " -0.029506497085094452,\n",
       " -0.9679375886917114,\n",
       " -0.25521859526634216,\n",
       " 0.51478111743927,\n",
       " -0.23642002046108246,\n",
       " 0.28468582034111023,\n",
       " 0.31897181272506714,\n",
       " -0.5844506025314331,\n",
       " 0.5921885967254639,\n",
       " 0.38849183917045593,\n",
       " 0.145851269364357,\n",
       " 1.8491928577423096,\n",
       " -0.0019615115597844124,\n",
       " 0.20504812896251678,\n",
       " -0.07622698694467545,\n",
       " -0.5249322056770325,\n",
       " -9.496620623394847e-05,\n",
       " 0.2517397403717041,\n",
       " -0.18088306486606598,\n",
       " 0.8640104532241821,\n",
       " -0.12315292656421661,\n",
       " -0.6349971890449524,\n",
       " -0.24866925179958344,\n",
       " 0.8942517042160034,\n",
       " 0.07045336812734604,\n",
       " -0.12172584235668182,\n",
       " -0.23469164967536926,\n",
       " 1.1381057500839233,\n",
       " -0.2997276782989502,\n",
       " -0.3226175606250763,\n",
       " 0.2705387771129608,\n",
       " 0.4494796395301819,\n",
       " -1.0925341844558716,\n",
       " 0.29459425806999207,\n",
       " -0.982613205909729,\n",
       " 0.5152333378791809,\n",
       " 0.21429498493671417,\n",
       " -0.8650507926940918,\n",
       " 0.35434362292289734,\n",
       " -1.2418570518493652,\n",
       " -1.5183311700820923,\n",
       " 0.502095639705658,\n",
       " 0.4419521391391754,\n",
       " 0.22403360903263092,\n",
       " -0.45928552746772766,\n",
       " 0.6165559887886047,\n",
       " -0.025760915130376816,\n",
       " 0.1172180026769638,\n",
       " 0.24718639254570007,\n",
       " -0.5861758589744568,\n",
       " -0.11295744776725769,\n",
       " -0.4593060314655304,\n",
       " -0.9265115261077881,\n",
       " 0.058606114238500595,\n",
       " 0.31906595826148987,\n",
       " -0.6818931698799133,\n",
       " 0.20952418446540833,\n",
       " 0.01181565411388874,\n",
       " 0.13897110521793365,\n",
       " 0.5202915668487549,\n",
       " -0.3343006372451782,\n",
       " -0.28238293528556824,\n",
       " -0.3789657652378082,\n",
       " 0.3735840916633606,\n",
       " -0.3942633271217346,\n",
       " 0.5176234841346741,\n",
       " -0.20000073313713074,\n",
       " -0.3171432614326477,\n",
       " -0.6158896088600159,\n",
       " -0.28302493691444397,\n",
       " -0.138807475566864,\n",
       " -0.23670227825641632,\n",
       " -0.8010297417640686,\n",
       " -0.6514990329742432,\n",
       " 0.8688864707946777,\n",
       " -0.08058007061481476,\n",
       " 0.5369605422019958,\n",
       " -0.5076857209205627,\n",
       " -0.21487820148468018,\n",
       " 0.04858025163412094,\n",
       " 0.47322648763656616,\n",
       " 0.732306718826294,\n",
       " -0.18722006678581238,\n",
       " 0.753868818283081,\n",
       " 1.4172812700271606,\n",
       " 0.3877178728580475,\n",
       " -0.2855130732059479,\n",
       " -0.5290355086326599,\n",
       " 0.9825008511543274,\n",
       " 0.38726964592933655,\n",
       " -0.10124784708023071,\n",
       " 0.1152258887887001,\n",
       " -0.5040314197540283,\n",
       " -0.0946471318602562,\n",
       " 0.4486880898475647,\n",
       " 0.07744763791561127,\n",
       " -0.37680959701538086,\n",
       " 0.34438806772232056,\n",
       " -0.21230269968509674,\n",
       " -0.7534362077713013,\n",
       " -0.4878282845020294,\n",
       " -0.6833606958389282,\n",
       " -0.4149402976036072,\n",
       " -0.3781261444091797,\n",
       " 0.15115636587142944,\n",
       " 0.05063563212752342,\n",
       " 0.5623219609260559,\n",
       " 0.21697187423706055,\n",
       " 0.12244414538145065,\n",
       " -0.5291175842285156,\n",
       " 0.22678621113300323,\n",
       " 0.14309698343276978,\n",
       " 0.606138288974762,\n",
       " -0.22695329785346985,\n",
       " 0.5133046507835388,\n",
       " 0.2737791836261749,\n",
       " 0.8348243236541748,\n",
       " -0.9504677057266235,\n",
       " 0.2694412171840668,\n",
       " 0.4895024597644806,\n",
       " -0.7235133647918701,\n",
       " 0.5224657654762268,\n",
       " -0.19560670852661133,\n",
       " 0.20055502653121948,\n",
       " -0.17426607012748718,\n",
       " 0.12928444147109985,\n",
       " -0.5385251045227051,\n",
       " 0.150926873087883,\n",
       " 0.12414232641458511,\n",
       " -1.956925392150879,\n",
       " 0.6426180601119995,\n",
       " 0.14838165044784546,\n",
       " 0.026481367647647858,\n",
       " 0.3941836655139923,\n",
       " -0.18309567868709564,\n",
       " -0.7059903144836426,\n",
       " 0.42168450355529785,\n",
       " -0.1523910015821457,\n",
       " 0.7992497086524963,\n",
       " -0.2873993217945099,\n",
       " -0.2895340621471405,\n",
       " -0.5940916538238525,\n",
       " -0.06435419619083405,\n",
       " 1.0710608959197998,\n",
       " -0.35089537501335144,\n",
       " -0.02459551766514778,\n",
       " -0.12722766399383545,\n",
       " -0.21972815692424774,\n",
       " -0.002298691775649786,\n",
       " -0.7103801965713501,\n",
       " 0.09167996048927307,\n",
       " 0.24844755232334137,\n",
       " -0.058973293751478195,\n",
       " -0.19395124912261963,\n",
       " 0.21867546439170837,\n",
       " -0.01828043907880783,\n",
       " 0.33806440234184265,\n",
       " -0.03729349374771118,\n",
       " 0.6053394675254822,\n",
       " -0.14458534121513367,\n",
       " -0.6118758320808411,\n",
       " -0.8657940030097961,\n",
       " -0.06972609460353851,\n",
       " 0.6852595210075378,\n",
       " 0.0009290353045798838,\n",
       " 0.8901302218437195,\n",
       " 0.8243947625160217,\n",
       " 0.7481379508972168,\n",
       " 0.3523499667644501,\n",
       " 0.004423393867909908,\n",
       " 0.44962042570114136,\n",
       " 0.8840405344963074,\n",
       " -0.05116434395313263,\n",
       " 1.1779134273529053,\n",
       " 0.09874387085437775,\n",
       " -0.2591303288936615,\n",
       " 0.11512579023838043,\n",
       " -0.4502471387386322,\n",
       " 0.054213378578424454,\n",
       " 0.0520627498626709,\n",
       " 0.3762451708316803,\n",
       " -0.11975760757923126,\n",
       " -0.6461306214332581,\n",
       " 0.5116831660270691,\n",
       " -0.37236884236335754,\n",
       " -0.39882004261016846,\n",
       " 0.5652796030044556,\n",
       " -1.137589931488037,\n",
       " -0.06219297647476196,\n",
       " 0.539413332939148,\n",
       " -0.30522775650024414,\n",
       " -0.820275604724884,\n",
       " -0.11434629559516907,\n",
       " -0.5443823337554932,\n",
       " -0.08983870595693588,\n",
       " 0.06278795003890991,\n",
       " -0.4360630512237549,\n",
       " -0.30637964606285095,\n",
       " 0.14124557375907898,\n",
       " 0.25428321957588196,\n",
       " -0.0959964245557785,\n",
       " -0.3809521496295929,\n",
       " 0.45526307821273804,\n",
       " 0.24089932441711426,\n",
       " 0.0647762268781662,\n",
       " 0.1020144373178482,\n",
       " -0.17790350317955017,\n",
       " 0.02376348339021206,\n",
       " -0.5300377011299133,\n",
       " 0.7267988324165344,\n",
       " -0.48800423741340637,\n",
       " 0.04992900416254997,\n",
       " 0.8657988905906677,\n",
       " -0.10276391357183456,\n",
       " 0.7524504661560059,\n",
       " -0.07438012957572937,\n",
       " -0.35370349884033203,\n",
       " -0.5648001432418823,\n",
       " 0.6444141864776611,\n",
       " -0.8473666310310364,\n",
       " -0.7212979197502136,\n",
       " 0.018771059811115265,\n",
       " 0.6645063161849976,\n",
       " -0.09317740052938461,\n",
       " -1.2219908237457275,\n",
       " -0.07504715770483017,\n",
       " -0.3751445412635803,\n",
       " -0.2797236740589142,\n",
       " -0.29509466886520386,\n",
       " -0.040510062128305435,\n",
       " 0.028440335765480995,\n",
       " 0.7966260313987732,\n",
       " -0.3838169574737549,\n",
       " -0.2439848929643631,\n",
       " -0.028430119156837463,\n",
       " 0.6136695146560669,\n",
       " 0.05600866302847862,\n",
       " -0.5296719670295715,\n",
       " 0.14117376506328583,\n",
       " 0.45822852849960327,\n",
       " -0.6955926418304443,\n",
       " 0.01985865645110607,\n",
       " 0.032379407435655594,\n",
       " 0.38711151480674744,\n",
       " -0.41918322443962097,\n",
       " 0.5172672867774963,\n",
       " -0.18118935823440552,\n",
       " 1.4542977809906006,\n",
       " 0.47162559628486633,\n",
       " 0.3252599835395813,\n",
       " -0.21516060829162598,\n",
       " 1.0769145488739014,\n",
       " -0.09354616701602936,\n",
       " -0.45882952213287354,\n",
       " 0.1854078322649002,\n",
       " -0.36644014716148376,\n",
       " 0.8029113411903381,\n",
       " -0.4796975255012512,\n",
       " 0.06638305634260178,\n",
       " 0.4528610408306122,\n",
       " 0.5124975442886353,\n",
       " 0.7922964692115784,\n",
       " 1.4846465587615967,\n",
       " 0.3915199339389801,\n",
       " -0.82930988073349,\n",
       " -0.41631436347961426,\n",
       " 0.5418475270271301,\n",
       " -0.6887208819389343,\n",
       " 0.7662532329559326,\n",
       " -0.03115488775074482,\n",
       " -0.2230786830186844,\n",
       " 0.21139375865459442,\n",
       " 0.0786307156085968,\n",
       " -0.6137111783027649,\n",
       " 0.30726733803749084,\n",
       " 0.1330236941576004,\n",
       " 0.8459998369216919,\n",
       " 0.023454749956727028,\n",
       " 0.003803896252065897,\n",
       " 0.19909308850765228,\n",
       " 0.3137660324573517,\n",
       " -0.35469797253608704,\n",
       " -0.1826363056898117,\n",
       " -0.3199526071548462,\n",
       " -0.05911136418581009,\n",
       " -0.8597374558448792,\n",
       " 0.21844889223575592,\n",
       " 0.13508927822113037,\n",
       " -0.004976380616426468,\n",
       " 0.9053189754486084,\n",
       " 0.25615301728248596,\n",
       " 0.6543776988983154,\n",
       " 0.9940353035926819,\n",
       " 0.24194298684597015,\n",
       " 0.26557254791259766,\n",
       " 0.192827507853508,\n",
       " 0.5181142687797546,\n",
       " -0.11805562674999237,\n",
       " 0.07006854563951492,\n",
       " -1.0591434240341187,\n",
       " 0.34699565172195435,\n",
       " -0.32368963956832886,\n",
       " -0.6614789366722107,\n",
       " -0.22553060948848724,\n",
       " -0.34107905626296997,\n",
       " 0.5639438629150391,\n",
       " 0.22138656675815582,\n",
       " -0.357509046792984,\n",
       " 0.45010846853256226,\n",
       " -0.1256004273891449,\n",
       " -0.5559214353561401,\n",
       " -0.37937119603157043,\n",
       " -0.0260622501373291,\n",
       " -0.8561735153198242,\n",
       " 0.45278218388557434,\n",
       " 0.3178689479827881,\n",
       " -0.17520278692245483,\n",
       " 0.4256420135498047,\n",
       " 0.24677516520023346,\n",
       " -0.14897900819778442,\n",
       " -0.9275633692741394,\n",
       " 0.7548919320106506,\n",
       " 0.5304873585700989,\n",
       " 0.4520696997642517,\n",
       " 0.9190335869789124,\n",
       " -0.5779633522033691,\n",
       " -1.811972975730896,\n",
       " -0.3737297058105469,\n",
       " 0.39185455441474915,\n",
       " 0.28842800855636597,\n",
       " -0.36990126967430115,\n",
       " 1.1383615732192993,\n",
       " 0.07473772764205933,\n",
       " -0.15688274800777435,\n",
       " 0.010167628526687622,\n",
       " -0.5341393351554871,\n",
       " -0.20729079842567444,\n",
       " 0.5918828845024109,\n",
       " 0.43244850635528564,\n",
       " -0.060969702899456024,\n",
       " 0.32362833619117737,\n",
       " 0.350490927696228,\n",
       " 0.6927768588066101,\n",
       " -1.2517305612564087,\n",
       " -0.1799379289150238,\n",
       " -0.47370806336402893,\n",
       " -0.06793402135372162,\n",
       " 0.06271272152662277,\n",
       " -0.5054192543029785,\n",
       " -0.9258170127868652,\n",
       " -0.8722351789474487,\n",
       " -0.07678481191396713,\n",
       " 0.5114560127258301,\n",
       " -0.409134179353714,\n",
       " 0.09409864246845245,\n",
       " 0.684414803981781,\n",
       " -0.1960761845111847,\n",
       " 0.21407541632652283,\n",
       " 0.34790128469467163,\n",
       " 0.19951871037483215,\n",
       " 0.4283077120780945,\n",
       " 0.11694636195898056,\n",
       " -1.0380336046218872,\n",
       " 0.05521863326430321,\n",
       " -0.02589695155620575,\n",
       " 0.1902036815881729,\n",
       " -0.12837113440036774,\n",
       " 1.0900930166244507,\n",
       " -0.6731725931167603,\n",
       " 0.06340740621089935,\n",
       " -0.08206278830766678,\n",
       " 0.3036669194698334,\n",
       " 0.5791518688201904,\n",
       " -0.23093363642692566,\n",
       " 0.647730827331543,\n",
       " -0.4309796094894409,\n",
       " 0.0966494157910347,\n",
       " -0.25317418575286865,\n",
       " 0.6496443748474121,\n",
       " -0.5065729022026062,\n",
       " 0.4931815266609192,\n",
       " -0.0020261891186237335,\n",
       " 0.08793146908283234,\n",
       " -0.6040776371955872,\n",
       " 0.20256176590919495,\n",
       " -0.7932512760162354,\n",
       " -0.17712344229221344,\n",
       " 0.2969858944416046,\n",
       " -0.4371984004974365,\n",
       " 0.23185192048549652,\n",
       " -0.709553062915802,\n",
       " -0.7062073945999146,\n",
       " 0.1785416454076767,\n",
       " -0.16536945104599,\n",
       " 0.03451181948184967,\n",
       " -0.7184118628501892,\n",
       " 0.5062878131866455,\n",
       " -0.42058616876602173,\n",
       " 0.6230908632278442,\n",
       " 0.7863969206809998,\n",
       " 0.13677562773227692,\n",
       " 0.038899317383766174,\n",
       " 0.6706513166427612,\n",
       " 0.46858498454093933,\n",
       " 0.2588374614715576,\n",
       " -0.6289772987365723,\n",
       " -1.1858983039855957,\n",
       " 0.8022279739379883,\n",
       " -0.1274658888578415,\n",
       " -0.090317003428936,\n",
       " 0.20199857652187347,\n",
       " -4.66832160949707,\n",
       " -0.37366700172424316,\n",
       " -0.493166983127594,\n",
       " 0.1337907612323761,\n",
       " 0.34258103370666504,\n",
       " -0.8031890988349915,\n",
       " -0.3128965497016907,\n",
       " 0.2673207223415375,\n",
       " 0.3114168643951416,\n",
       " -0.06181745603680611,\n",
       " 0.4412917196750641,\n",
       " 0.08142668753862381,\n",
       " -0.08258245885372162,\n",
       " -0.723294734954834,\n",
       " 1.013631820678711,\n",
       " 0.37661507725715637]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ds_20k[0]['embeddings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63a36ed44ae4c9eb769c3f1bed5bd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_ds_20k.save_to_disk('eli5_dataset_title_text_20k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24d31345952407e91777c584916b1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a057a72f133f4e6b8248032fe32de751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "hub_token = os.environ['HUGGINGFACE_TOKEN']\n",
    "\n",
    "token_ds_20k.push_to_hub ('eli5_dataset_title_text_20k',token=hub_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del token_ds_20k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971dc744349d4138a4200452ed7f94e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1442904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 74\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Lets tokenize the whole dataset and save it to disk\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m token_ds \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m x : {\u001b[39m'\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m'\u001b[39;49m : model_last_hidden_state(x) }) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m token_ds\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    591\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 592\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    593\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    554\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    555\u001b[0m }\n\u001b[0;32m    556\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    558\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    559\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:3097\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3090\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3091\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   3092\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3093\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3094\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[0;32m   3095\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3096\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3097\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3098\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   3099\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:3450\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3448\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   3449\u001b[0m \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3450\u001b[0m     example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[0;32m   3451\u001b[0m     \u001b[39mif\u001b[39;00m update_data:\n\u001b[0;32m   3452\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:3353\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3351\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[0;32m   3352\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[1;32m-> 3353\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[0;32m   3354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3355\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[0;32m   3356\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[0;32m   3357\u001b[0m     }\n",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 74\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Lets tokenize the whole dataset and save it to disk\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m token_ds \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x : {\u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m : model_last_hidden_state(x) }) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m token_ds\n",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 74\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_last_hidden_state\u001b[39m (row):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   token \u001b[39m=\u001b[39m tokenizer(row[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m'\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y141sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtoken)[\u001b[39m\"\u001b[39m\u001b[39mlast_hidden_state\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\tokenization_utils_base.py:2602\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2600\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2601\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2602\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[0;32m   2603\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2604\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\tokenization_utils_base.py:2708\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2688\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2689\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2690\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2705\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2706\u001b[0m     )\n\u001b[0;32m   2707\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2708\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_plus(\n\u001b[0;32m   2709\u001b[0m         text\u001b[39m=\u001b[39;49mtext,\n\u001b[0;32m   2710\u001b[0m         text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[0;32m   2711\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m   2712\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   2713\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[0;32m   2714\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m   2715\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m   2716\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m   2717\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m   2718\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m   2719\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m   2720\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m   2721\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m   2722\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m   2723\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m   2724\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m   2725\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2726\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2727\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\tokenization_utils_base.py:2781\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2771\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2772\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2773\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   2774\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2778\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2779\u001b[0m )\n\u001b[1;32m-> 2781\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_plus(\n\u001b[0;32m   2782\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[0;32m   2783\u001b[0m     text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[0;32m   2784\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m   2785\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[0;32m   2786\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[0;32m   2787\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m   2788\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m   2789\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m   2790\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m   2791\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m   2792\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m   2793\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m   2794\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m   2795\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m   2796\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m   2797\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m   2798\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2799\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2800\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\tokenization_utils_fast.py:524\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode_plus\u001b[39m(\n\u001b[0;32m    503\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    504\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BatchEncoding:\n\u001b[0;32m    523\u001b[0m     batched_input \u001b[39m=\u001b[39m [(text, text_pair)] \u001b[39mif\u001b[39;00m text_pair \u001b[39melse\u001b[39;00m [text]\n\u001b[1;32m--> 524\u001b[0m     batched_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[0;32m    525\u001b[0m         batched_input,\n\u001b[0;32m    526\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m    527\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    528\u001b[0m         padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[0;32m    529\u001b[0m         truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[0;32m    530\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m    531\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m    532\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m    533\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m    534\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m    535\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m    536\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m    537\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m    538\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m    539\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m    540\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    541\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    542\u001b[0m     )\n\u001b[0;32m    544\u001b[0m     \u001b[39m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    545\u001b[0m     \u001b[39m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    546\u001b[0m     \u001b[39mif\u001b[39;00m return_tensors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\tokenization_utils_fast.py:452\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_truncation_and_padding(\n\u001b[0;32m    445\u001b[0m     padding_strategy\u001b[39m=\u001b[39mpadding_strategy,\n\u001b[0;32m    446\u001b[0m     truncation_strategy\u001b[39m=\u001b[39mtruncation_strategy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    450\u001b[0m )\n\u001b[1;32m--> 452\u001b[0m encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenizer\u001b[39m.\u001b[39;49mencode_batch(\n\u001b[0;32m    453\u001b[0m     batch_text_or_text_pairs,\n\u001b[0;32m    454\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    455\u001b[0m     is_pretokenized\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m    456\u001b[0m )\n\u001b[0;32m    458\u001b[0m \u001b[39m# Convert encoding to dict\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[39m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[39m#                       List[EncodingFast]\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[39m#                    ]\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[0;32m    464\u001b[0m tokens_and_encodings \u001b[39m=\u001b[39m [\n\u001b[0;32m    465\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_encoding(\n\u001b[0;32m    466\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m     \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m encodings\n\u001b[0;32m    476\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lets tokenize the whole dataset and save it to disk\n",
    "token_ds = dataset.map(lambda x : {'embeddings' : model_last_hidden_state(x) }) \n",
    "token_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must install Faiss to use FaissIndex. To do so you can run `conda install -c pytorch faiss-cpu` or `conda install -c pytorch faiss-gpu`. A community supported package is also available on pypi: `pip install faiss-cpu` or `pip install faiss-gpu`. Note that pip may not have the latest version of FAISS, and thus, some of the latest features and bug fixes may not be available.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Safeer\\Documents\\LLM_Practice\\Question-Answering-with-LLM\\Question_answering_with_T5.ipynb Cell 74\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Safeer/Documents/LLM_Practice/Question-Answering-with-LLM/Question_answering_with_T5.ipynb#Y133sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m token_ds_100\u001b[39m.\u001b[39;49madd_faiss_index(column\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39membeddings\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\arrow_dataset.py:5695\u001b[0m, in \u001b[0;36mDataset.add_faiss_index\u001b[1;34m(self, column, index_name, device, string_factory, metric_type, custom_index, batch_size, train_size, faiss_verbose, dtype)\u001b[0m\n\u001b[0;32m   5641\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Add a dense index using Faiss for fast retrieval.\u001b[39;00m\n\u001b[0;32m   5642\u001b[0m \u001b[39mBy default the index is done over the vectors of the specified column.\u001b[39;00m\n\u001b[0;32m   5643\u001b[0m \u001b[39mYou can specify `device` if you want to run it on GPU (`device` must be the GPU index).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5692\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[0;32m   5693\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5694\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformatted_as(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, columns\u001b[39m=\u001b[39m[column], dtype\u001b[39m=\u001b[39mdtype):\n\u001b[1;32m-> 5695\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49madd_faiss_index(\n\u001b[0;32m   5696\u001b[0m         column\u001b[39m=\u001b[39;49mcolumn,\n\u001b[0;32m   5697\u001b[0m         index_name\u001b[39m=\u001b[39;49mindex_name,\n\u001b[0;32m   5698\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m   5699\u001b[0m         string_factory\u001b[39m=\u001b[39;49mstring_factory,\n\u001b[0;32m   5700\u001b[0m         metric_type\u001b[39m=\u001b[39;49mmetric_type,\n\u001b[0;32m   5701\u001b[0m         custom_index\u001b[39m=\u001b[39;49mcustom_index,\n\u001b[0;32m   5702\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   5703\u001b[0m         train_size\u001b[39m=\u001b[39;49mtrain_size,\n\u001b[0;32m   5704\u001b[0m         faiss_verbose\u001b[39m=\u001b[39;49mfaiss_verbose,\n\u001b[0;32m   5705\u001b[0m     )\n\u001b[0;32m   5706\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\search.py:480\u001b[0m, in \u001b[0;36mIndexableMixin.add_faiss_index\u001b[1;34m(self, column, index_name, device, string_factory, metric_type, custom_index, batch_size, train_size, faiss_verbose)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Add a dense index using Faiss for fast retrieval.\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[39mThe index is created using the vectors of the specified column.\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[39mYou can specify `device` if you want to run it on GPU (`device` must be the GPU index, see more below).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39m    faiss_verbose (`bool`, defaults to False): Enable the verbosity of the Faiss index.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    479\u001b[0m index_name \u001b[39m=\u001b[39m index_name \u001b[39mif\u001b[39;00m index_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m column\n\u001b[1;32m--> 480\u001b[0m faiss_index \u001b[39m=\u001b[39m FaissIndex(\n\u001b[0;32m    481\u001b[0m     device\u001b[39m=\u001b[39;49mdevice, string_factory\u001b[39m=\u001b[39;49mstring_factory, metric_type\u001b[39m=\u001b[39;49mmetric_type, custom_index\u001b[39m=\u001b[39;49mcustom_index\n\u001b[0;32m    482\u001b[0m )\n\u001b[0;32m    483\u001b[0m faiss_index\u001b[39m.\u001b[39madd_vectors(\n\u001b[0;32m    484\u001b[0m     \u001b[39mself\u001b[39m, column\u001b[39m=\u001b[39mcolumn, batch_size\u001b[39m=\u001b[39mbatch_size, train_size\u001b[39m=\u001b[39mtrain_size, faiss_verbose\u001b[39m=\u001b[39mfaiss_verbose\n\u001b[0;32m    485\u001b[0m )\n\u001b[0;32m    486\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indexes[index_name] \u001b[39m=\u001b[39m faiss_index\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\datasets\\search.py:247\u001b[0m, in \u001b[0;36mFaissIndex.__init__\u001b[1;34m(self, device, string_factory, metric_type, custom_index)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfaiss_index \u001b[39m=\u001b[39m custom_index\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_faiss:\n\u001b[1;32m--> 247\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must install Faiss to use FaissIndex. To do so you can run `conda install -c pytorch faiss-cpu` or `conda install -c pytorch faiss-gpu`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA community supported package is also available on pypi: `pip install faiss-cpu` or `pip install faiss-gpu`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pip may not have the latest version of FAISS, and thus, some of the latest features and bug fixes may not be available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: You must install Faiss to use FaissIndex. To do so you can run `conda install -c pytorch faiss-cpu` or `conda install -c pytorch faiss-gpu`. A community supported package is also available on pypi: `pip install faiss-cpu` or `pip install faiss-gpu`. Note that pip may not have the latest version of FAISS, and thus, some of the latest features and bug fixes may not be available."
     ]
    }
   ],
   "source": [
    "token_ds_100.add_faiss_index(column='embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
